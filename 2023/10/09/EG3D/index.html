<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://zjwfufu.github.io">
  <title>Efficient Geometry-aware 3D GANs | 我起初心向明月</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="​    “暮雨沾轻裘，声色随性收。弦歌久，续盏酬，结客少年游；落花踏尽信马走，风盈袖。天地旋袂划星斗，白月隐辰宿。“">
<meta property="og:type" content="article">
<meta property="og:title" content="Efficient Geometry-aware 3D GANs">
<meta property="og:url" content="https://zjwfufu.github.io/2023/10/09/EG3D/index.html">
<meta property="og:site_name" content="我起初心向明月">
<meta property="og:description" content="​    “暮雨沾轻裘，声色随性收。弦歌久，续盏酬，结客少年游；落花踏尽信马走，风盈袖。天地旋袂划星斗，白月隐辰宿。“">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_1.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_2.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_3.gif">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_4.gif">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_5.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_6.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_7.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_8.jpg">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_ffhq.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_v.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_2077.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_ffhq.gif">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_v.gif">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_2077.gif">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_miku_0.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_miku_1.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_foreign1.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_foreign2.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_foreign3.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_asian1.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_asian2.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/inversion/eg3d_asian3.png">
<meta property="og:image" content="https://zjwfufu.github.io/images/eg3d_end.jpg">
<meta property="article:published_time" content="2023-10-09T02:39:52.000Z">
<meta property="article:modified_time" content="2024-01-06T02:11:07.525Z">
<meta property="article:author" content="张嘉伟">
<meta property="article:tag" content="3DV">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zjwfufu.github.io/images/eg3d_1.jpg">
  
    <link rel="alternative" href="/atom.xml" title="我起初心向明月" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/sigma.ico">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#ccc,#48D1CC);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow"  style="background: linear-gradient(120deg,#6699ff,#48D1CC)">
      
<div class="overlay" style="background: rgba(0,0,0,0)"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/me.png" class="js-avatar">
		</a>
		<div class="contain">
			<p style="font-size:20px;color:white">zjw's blog</p>
		</div>
		<div class="contain">
			<p style="font-size:20px;color:white">我起初心向明月，却不知明月何意。</p>
		</div>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/archives">归档</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
				<li><a href="/tags">标签</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/zjwfufu" title="github"><i class="icon-github"></i></a>
		        
					<a class="home" target="_blank" href="https://zjwsite.github.io/" title="home"><i class="icon-home"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:jiaweizhang.fufu@gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse" style="background: undefined">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: rgba(0,0,0,0)"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/me.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/zjwfufu" title="github"><i class="icon-github"></i></a>
			        
						<a class="home" target="_blank" href="https://zjwsite.github.io/" title="home"><i class="icon-home"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:jiaweizhang.fufu@gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 25%"><a href="/">主页</a></li>
		        
					<li style="width: 25%"><a href="/archives">归档</a></li>
		        
					<li style="width: 25%"><a href="/categories">分类</a></li>
		        
					<li style="width: 25%"><a href="/tags">标签</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-EG3D" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Efficient Geometry-aware 3D GANs
    </h1>
  

		<!--显示阅读次数-->
		
		  <br/>
		  <a class="cloud-tie-join-count" href="javascript:void(0);" style="color:gray;font-size:14px;">
		  <span class="icon-sort"></span>
		  <span id="busuanzi_container_page_pv" style="color:#ef7522;font-size:14px;">
					阅读数: <span id="busuanzi_value_page_pv"></span>次 &nbsp;&nbsp;
		  </span>
		  </a>
		
		<!--显示阅读次数完毕-->
        
        <a href="/2023/10/09/EG3D/" class="archive-article-date">
  	<time datetime="2023-10-09T02:39:52.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-09</time>
</a>
        
      </header>
    
    
	<div class="article-entry" itemprop="articleBody">
      
	  
		
		  <div id="custom-toc" class="custom-toc-article">
			<strong class="toc-title">文章目录</strong>
			<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Overview"><span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Analysis"><span class="toc-text">Code Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#config-setting"><span class="toc-text">config setting</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#click%E5%8F%96%E4%BB%A3argsparse"><span class="toc-text">@click取代argsparse</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%AF%BC%E5%85%A5"><span class="toc-text">动态导入</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#launch-training"><span class="toc-text">launch training</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#DP%E4%B8%8EDDP%E7%9A%84%E5%85%A5%E9%97%A8"><span class="toc-text">DP与DDP的入门</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#training-loop"><span class="toc-text">training loop</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B2%A1%E7%94%A8%E8%BF%87sampler%EF%BC%9F"><span class="toc-text">没用过sampler？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%80%9C%E6%8C%81%E4%B9%85%E5%8C%96%E2%80%9D%E7%9A%84%E7%94%A8%E5%A4%84"><span class="toc-text">“持久化”的用处</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E5%BE%AA%E7%8E%AF%E4%BD%93"><span class="toc-text">构造循环体</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#accumulate-gradients"><span class="toc-text">accumulate gradients</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Non-saturating-or-saturating"><span class="toc-text">Non-saturating or saturating</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#R1-regularization"><span class="toc-text">R1 regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Density-regularization"><span class="toc-text">Density regularization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%80%9CEG3D%E2%80%9D"><span class="toc-text">“EG3D”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Mapping-Network"><span class="toc-text">Mapping Network</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#pose-swapping-regularization"><span class="toc-text">pose swapping regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#style-mixing-regularization"><span class="toc-text">style mixing regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Truncation-trick"><span class="toc-text">Truncation trick</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Generator"><span class="toc-text">Generator</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Tri-plane-3D-representation"><span class="toc-text">Tri-plane 3D representation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Tri-plane-intuition"><span class="toc-text">Tri-plane intuition</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Discriminator"><span class="toc-text">Discriminator</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Trailer"><span class="toc-text">Trailer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#End"><span class="toc-text">End</span></a></li></ol>
		  </div>
		
	  
        <p>​    “暮雨沾轻裘，声色随性收。弦歌久，续盏酬，结客少年游；落花踏尽信马走，风盈袖。天地旋袂划星斗，白月隐辰宿。“</p>
<span id="more"></span><!--toc-->
<p>​    EG3D是一篇nVidia参与的基于单视角的2D图片，生成3D形状的工作，其生成的结果兼具几何和视角上的一致性。EG3D整个工作其实由许多部分和细节组成，文中由于篇幅，以及“科技论文”写作时的要求，对于大量的细节基本就是一带而过，这就导致理解这篇时会非常困难。为了透彻的理解这篇工作，首先需要了解NeRF，GAN，然后进一步要了解StyleGAN系列。因为以及其中用到的一些技术严格来讲横跨StyleGAN，StyleGAN2，StyleGAN3。</p>
<p>​    除了纸面的“contributions”，EG3D的代码库也已经很有学习价值了，其代码给出了一个非常先进的深度学习项目管线。后面许多的工作都沿用了他们代码的pipeline，例如<a target="_blank" rel="noopener" href="https://github.com/MrTornado24/Next3D">Next3D</a>，<a target="_blank" rel="noopener" href="https://github.com/ShuhongChen/panic3d-anime-reconstruction">panic3D</a>，<a target="_blank" rel="noopener" href="https://github.com/dunbar12138/pix2pix3D">pix2pix3D</a>。</p>
<blockquote>
<p>“工欲善其事，必先利其器。”</p>
</blockquote>
<p>​    这篇blog会先大概从论文中的整个流程切入，然后直接解读一下代码。适合对3D生成感兴趣以及跟我一样不是很熟悉Python（或者说是“lack of skill”）的读者进行阅读。对于文中涉及到的StyleGAN系列知识，blog中不会过度的展开，感兴趣的可以自行查阅：</p>
<blockquote>
<p>StyleGAN -&gt; <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.04948">A Style-Based Generator Architecture for Generative Adversarial Networks</a></p>
<p>StyleGAN2 -&gt; <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.04958">Analyzing and Improving the Image Quality of StyleGAN</a></p>
<p>StyleGAN3 -&gt; <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.12423">Alias-Free Generative Adversarial Networks</a></p>
<p>实际上EG3D的作者后面有<a target="_blank" rel="noopener" href="https://research.nvidia.com/person/tero-karras">Tero Karras</a>的署名。我在炼丹里最喜欢的工作基本都是他的力作，例如<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.10196">PGGAN</a>，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.12423">StyleGAN3</a>。其中后者的强度基本是给炼丹者一点小小的数字信号处理震撼，以及这一篇：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2206.00364">Elucidating the Design Space of Diffusion-Based Generative Models</a>，一个恐怖的diffusion实验报告，基本把diffusion里的各个部件都“测量”了一遍，然后给出了很多实践意义上的指导。</p>
</blockquote>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><center>
    <img src='/images/eg3d_1.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    如图所示，EG3D描述了这么一件事：</p>
<ul>
<li>给出一个服从告诉分布的Latent code $\mathbf{z}$，送进一个Mapping Network（在StyleGAN系列中，这一般是8层MLP，用来给编码用的隐空间“塑形”），和一个相机位姿$\mathbf{p}$一起构造一个联合分布。[Tips: 粗糙的阅读原文后，我们可以知道EG3D实验的重头戏是在FFHQ和AFHQv2 Cats两个images dataset，本质上就是高清的人脸和猫猫脸数据集。所以其本身是没有拍摄时相机的位姿$\mathbf{p}$这个label的，这个label其实是他们用其他工作的相机位姿估计器估计的，后面再玩GAN inversion时我们会再次提到。]</li>
<li>Mapping后的结果，通过mod.（意为modulate，是StyleGAN中的一个称呼，其实就是用一种特殊的方式输入进NN里）送进StyleGAN的生成器。</li>
<li>在GAN的常规剧情下，最后会用一个输入通道为$C_i$，输出通道为3的卷积层将$C_i$个特征图映回RGB空间。但这里好像是取了其中间结果，即那$C_i$个特征图（图中的256×256×96）。</li>
<li>然后这个特征图被一个比较稀奇的“Tri-planes representation”给操作了一下，得到$F_{XY},F_{XZ},F_{YZ}$，然后这三个东西逐元素相加，被一个decoder解码，得到Color和Density的表示，之后在$\mathbf{P}$的条件下，进行体渲染。这个过程即“Neural Renderer”。</li>
<li>注意Color的维度是32，而Density的维度是1。所以其实它是render了32张图，每个图用相同的geometry。然后这个128×128×32的$I_F$，不知道怎么的，就可以计算出128×128×3的$I_{RGB}$，然后由给它超分了一下，得到高分辨率的图像。</li>
<li>由于超分是个复杂的非线性操作，为了保证前后的图片细节的一致性。小分辨率的图会被上采样，然后这两个东西拼到一起来让判别器去分类。这被称为“dual discrimination”。</li>
<li>于是整个管线就可以反向传播了。</li>
</ul>
<p>​    上述概括是直接从图里得到了，具体实现还是得阅读<a target="_blank" rel="noopener" href="https://github.com/NVlabs/eg3d">EG3D</a>。</p>
<h3 id="Code-Analysis"><a href="#Code-Analysis" class="headerlink" title="Code Analysis"></a>Code Analysis</h3><p>​    整个项目结构是很干净的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── calc_metrics.py</span><br><span class="line">├── camera_utils.py</span><br><span class="line">├── dataset_tool.py</span><br><span class="line">├── environment.yml</span><br><span class="line">├── gen_samples.py</span><br><span class="line">├── gen_videos.py</span><br><span class="line">├── legacy.py</span><br><span class="line">├── shape_utils.py</span><br><span class="line">├── train.py</span><br><span class="line">├── visualizer.py</span><br><span class="line">├── dnnlib</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   └── util.py</span><br><span class="line">├── gui_utils</span><br><span class="line">│   ├── glfw_window.py</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── text_utils.py</span><br><span class="line">├── metrics</span><br><span class="line">│   ├── equivariance.py</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── precision_recall.py</span><br><span class="line">├── networks</span><br><span class="line">│   ├── afhqcats512-128.pkl</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── shapenetcars128-64.pkl</span><br><span class="line">├── torch_utils</span><br><span class="line">│   ├── custom_ops.py</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── misc.py</span><br><span class="line">│   ├── ops</span><br><span class="line">│   │   ├── bias_act.cpp</span><br><span class="line">│   │   ├── ...</span><br><span class="line">│   │   └── upfirdn2d.py</span><br><span class="line">│   ├── persistence.py</span><br><span class="line">│   └── training_stats.py</span><br><span class="line">├── training</span><br><span class="line">│   ├── augment.py</span><br><span class="line">│   ├── crosssection_utils.py</span><br><span class="line">│   ├── dataset.py</span><br><span class="line">│   ├── dual_discriminator.py</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── loss.py</span><br><span class="line">│   ├── networks_stylegan2.py</span><br><span class="line">│   ├── networks_stylegan3.py</span><br><span class="line">│   ├── superresolution.py</span><br><span class="line">│   ├── training_loop.py</span><br><span class="line">│   ├── triplane.py</span><br><span class="line">│   └── volumetric_rendering</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       ├── math_utils.py</span><br><span class="line">│       ├── ray_marcher.py</span><br><span class="line">│       ├── ray_sampler.py</span><br><span class="line">│       └── renderer.py</span><br><span class="line">└── viz</span><br><span class="line">    ├── backbone_cache_widget.py</span><br><span class="line">    ├── ...</span><br><span class="line">    └── zoom_widget.py</span><br></pre></td></tr></table></figure>
<p>​    这里<code>./dnnlib</code>下是一些常用的结构和类的实现，<code>./gui_utils</code>和<code>./viz</code>跟可视化和最后交互式的UI界面的呈现有关。<code>./networks</code>用于存放ckpt，<code>./metrics</code>是跟指标，质量评估相关的实现。<code>./torch_utils</code>里是从StyleGAN3中迁移过来的CUDA/C++扩展，<code>./training</code>里是具体的网络结构，损失函数，以及体渲染相关的实现。</p>
<p>​    我们一眼就能看出从train.py切入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main() <span class="comment"># pylint: disable=no-value-for-parameter</span></span><br></pre></td></tr></table></figure>
<h4 id="config-setting"><a href="#config-setting" class="headerlink" title="config setting"></a>config setting</h4><h5 id="click取代argsparse"><a href="#click取代argsparse" class="headerlink" title="@click取代argsparse"></a>@click取代argsparse</h5><p>​    我们注意到整个项目里，没有类似config的字眼，文件，文件夹出现，也没有熟悉的argparse和parser。这是因为EG3D用click来自定义了命令行参数。在<code>train.py</code>中的<code>main()</code>函数定义前：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Required.</span></span><br><span class="line"><span class="meta">@click.option(<span class="params"><span class="string">&#x27;--outdir&#x27;</span>,       <span class="built_in">help</span>=<span class="string">&#x27;Where to save the results&#x27;</span>, metavar=<span class="string">&#x27;DIR&#x27;</span>,                required=<span class="literal">True</span></span>)</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional features.</span></span><br><span class="line"><span class="meta">@click.option(<span class="params"><span class="string">&#x27;--cond&#x27;</span>,         <span class="built_in">help</span>=<span class="string">&#x27;Train conditional model&#x27;</span>, metavar=<span class="string">&#x27;BOOL&#x27;</span>,                 <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">True</span>, show_default=<span class="literal">True</span></span>)</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Misc hyperparameters.</span></span><br><span class="line"><span class="meta">@click.option(<span class="params"><span class="string">&#x27;--p&#x27;</span>,            <span class="built_in">help</span>=<span class="string">&#x27;Probability for --aug=fixed&#x27;</span>, metavar=<span class="string">&#x27;FLOAT&#x27;</span>,            <span class="built_in">type</span>=click.FloatRange(<span class="params"><span class="built_in">min</span>=<span class="number">0</span>, <span class="built_in">max</span>=<span class="number">1</span></span>), default=<span class="number">0.2</span>, show_default=<span class="literal">True</span></span>)</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Misc settings.</span></span><br><span class="line"><span class="meta">@click.option(<span class="params"><span class="string">&#x27;--desc&#x27;</span>,         <span class="built_in">help</span>=<span class="string">&#x27;String to include in result dir name&#x27;</span>, metavar=<span class="string">&#x27;STR&#x27;</span>,     <span class="built_in">type</span>=<span class="built_in">str</span></span>)</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># @click.option(&#x27;--sr_module&#x27;,    help=&#x27;Superresolution module&#x27;, metavar=&#x27;STR&#x27;,  type=str, required=True)</span></span><br><span class="line"><span class="meta">@click.option(<span class="params"><span class="string">&#x27;--neural_rendering_resolution_initial&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Resolution to render at&#x27;</span>, metavar=<span class="string">&#x27;INT&#x27;</span>,  <span class="built_in">type</span>=click.IntRange(<span class="params"><span class="built_in">min</span>=<span class="number">1</span></span>), default=<span class="number">64</span>, required=<span class="literal">False</span></span>)</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>​    用<code>@click.command()</code>来装饰<code>main()</code>函数，使用<code>@click.option</code>来定义各种选项。命令行中的关键字作为不定参数<code>**kwargs</code>输入进<code>main()</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@click.command()</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Train a GAN using the techniques described in the paper</span></span><br><span class="line"><span class="string">    &quot;Alias-Free Generative Adversarial Networks&quot;.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize config.</span></span><br><span class="line">    opts = dnnlib.EasyDict(kwargs) <span class="comment"># Command line arguments.</span></span><br><span class="line">    c = dnnlib.EasyDict() <span class="comment"># Main config dict.</span></span><br><span class="line">    c.G_kwargs = dnnlib.EasyDict(class_name=<span class="literal">None</span>, z_dim=<span class="number">512</span>, w_dim=<span class="number">512</span>, mapping_kwargs=dnnlib.EasyDict())</span><br><span class="line">    c.D_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;training.networks_stylegan2.Discriminator&#x27;</span>, block_kwargs=dnnlib.EasyDict(), mapping_kwargs=dnnlib.EasyDict(), epilogue_kwargs=dnnlib.EasyDict())</span><br><span class="line">    c.G_opt_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;torch.optim.Adam&#x27;</span>, betas=[<span class="number">0</span>,<span class="number">0.99</span>], eps=<span class="number">1e-8</span>)</span><br><span class="line">    c.D_opt_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;torch.optim.Adam&#x27;</span>, betas=[<span class="number">0</span>,<span class="number">0.99</span>], eps=<span class="number">1e-8</span>)</span><br><span class="line">    c.loss_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;training.loss.StyleGAN2Loss&#x27;</span>)</span><br><span class="line">    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=<span class="literal">True</span>, prefetch_factor=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>​    我们发现了一个被频繁使用的类：<code>EasyDict</code>，它被定义于<code>./dnnlib/util.py</code>中。其中dnnlib大概是deep neural network libraries之意：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EasyDict</span>(<span class="title class_ inherited__">dict</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convenience class that behaves like a dict but allows access with the attribute syntax.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getattr__</span>(<span class="params">self, name: <span class="built_in">str</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> self[name]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">raise</span> AttributeError(name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setattr__</span>(<span class="params">self, name: <span class="built_in">str</span>, value: <span class="type">Any</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self[name] = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delattr__</span>(<span class="params">self, name: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">del</span> self[name]</span><br></pre></td></tr></table></figure>
<p>​    这个类继承自Python原有的字典，重写了<code>__getattr__</code>, <code>__setattr__</code>, <code>__delattr__</code>三个魔法方法，从而允许我们可以直接用<code>&#39;dict.keys&#39;</code>的方式来获取其键值对，而不必写成<code>&#39;dict[&#39;keys]&#39;</code>，从而增加代码可读性（我应该在之前自己的一个项目里用这个的）。</p>
<p>​    所以实际上<code>main()</code>函数的initialize config阶段，是先将输入的<code>**kwargs</code>转换为<code>EasyDict</code>，然后定义一个主要的config，即<code>c</code>。接着在<code>c</code>中嵌套子字典，如生成器，判别器的参数<code>G_kwargs</code>, <code>D_kwargs</code>。以及他们的优化器的属性<code>G_opt_kwargs</code>, <code>D_opt_kwargs</code>等等。</p>
<p>​    接着会继续在<code>c</code>里注册参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment"># Training set.</span></span><br><span class="line">   c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Hyperparameters &amp; settings.</span></span><br><span class="line">   c.num_gpus = opts.gpus</span><br><span class="line">   c.batch_size = opts.batch</span><br><span class="line">   c.batch_gpu = opts.batch_gpu <span class="keyword">or</span> opts.batch // opts.gpus</span><br><span class="line">   c.G_kwargs.channel_base = c.D_kwargs.channel_base = opts.cbase</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Sanity checks.</span></span><br><span class="line">   <span class="keyword">if</span> c.batch_size % c.num_gpus != <span class="number">0</span>:</span><br><span class="line">       <span class="keyword">raise</span> click.ClickException(<span class="string">&#x27;--batch must be a multiple of --gpus&#x27;</span>)</span><br><span class="line">   ...</span><br><span class="line">   </span><br><span class="line">   <span class="comment"># Base configuration.</span></span><br><span class="line">   c.ema_kimg = c.batch_size * <span class="number">10</span> / <span class="number">32</span></span><br><span class="line">   c.G_kwargs.class_name = <span class="string">&#x27;training.triplane.TriPlaneGenerator&#x27;</span></span><br><span class="line">   c.D_kwargs.class_name = <span class="string">&#x27;training.dual_discriminator.DualDiscriminator&#x27;</span></span><br><span class="line">   </span><br><span class="line">   ...</span><br><span class="line">   </span><br><span class="line">   rendering_options = &#123;</span><br><span class="line">       <span class="string">&#x27;image_resolution&#x27;</span>: c.training_set_kwargs.resolution,</span><br><span class="line">       ...</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> opts.cfg == <span class="string">&#x27;ffhq&#x27;</span>:</span><br><span class="line">       rendering_options.update(&#123;</span><br><span class="line">           <span class="string">&#x27;depth_resolution&#x27;</span>: <span class="number">48</span>, <span class="comment"># number of uniform samples to take per ray.</span></span><br><span class="line">           ...</span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">elif</span> opts.cfg == <span class="string">&#x27;afhq&#x27;</span>:</span><br><span class="line">       rendering_options.update(&#123;</span><br><span class="line">           <span class="string">&#x27;depth_resolution&#x27;</span>: <span class="number">48</span>,</span><br><span class="line">           ...</span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">elif</span> opts.cfg == <span class="string">&#x27;shapenet&#x27;</span>:</span><br><span class="line">       rendering_options.update(&#123;</span><br><span class="line">           <span class="string">&#x27;depth_resolution&#x27;</span>: <span class="number">64</span>,</span><br><span class="line">           ...</span><br><span class="line">       &#125;)</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">       <span class="keyword">assert</span> <span class="literal">False</span>, <span class="string">&quot;Need to specify config&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> opts.density_reg &gt; <span class="number">0</span>:</span><br><span class="line">       ...</span><br><span class="line">   c.G_kwargs.rendering_kwargs = rendering_options</span><br><span class="line">   c.G_kwargs.num_fp16_res = <span class="number">0</span></span><br><span class="line">   c.loss_kwargs.blur_init_sigma = <span class="number">10</span> <span class="comment"># Blur the images seen by the discriminator.</span></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Augmentation.</span></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Resume.</span></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Performance-related toggles.</span></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> opts.nobench:</span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">   <span class="comment"># Description string.</span></span><br><span class="line">   desc = <span class="string">f&#x27;<span class="subst">&#123;opts.cfg:s&#125;</span>-<span class="subst">&#123;dataset_name:s&#125;</span>-gpus<span class="subst">&#123;c.num_gpus:d&#125;</span>-batch<span class="subst">&#123;c.batch_size:d&#125;</span>-gamma<span class="subst">&#123;c.loss_kwargs.r1_gamma:g&#125;</span>&#x27;</span></span><br><span class="line">   <span class="keyword">if</span> opts.desc <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">       desc += <span class="string">f&#x27;-<span class="subst">&#123;opts.desc&#125;</span>&#x27;</span></span><br></pre></td></tr></table></figure>
<h5 id="动态导入"><a href="#动态导入" class="headerlink" title="动态导入"></a>动态导入</h5><p>​    注意，我们发现，一些重要的配置，例如生成器和判别器的设置。我们好像仅仅只是写入了一堆字符串，并没有实例化什么类。实际上整个管线用<code>./dnnlib/util.py</code>中的如下的逻辑打包了动态导入（dynamic import）的过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_module_from_obj_name</span>(<span class="params">obj_name: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[types.ModuleType, <span class="built_in">str</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Searches for the underlying module behind the name to some python object.</span></span><br><span class="line"><span class="string">    Returns the module and the object name (original name with module part removed).&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># allow convenience shorthands, substitute them by full names</span></span><br><span class="line">    obj_name = re.sub(<span class="string">&quot;^np.&quot;</span>, <span class="string">&quot;numpy.&quot;</span>, obj_name)</span><br><span class="line">    obj_name = re.sub(<span class="string">&quot;^tf.&quot;</span>, <span class="string">&quot;tensorflow.&quot;</span>, obj_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># list alternatives for (module_name, local_obj_name)</span></span><br><span class="line">    parts = obj_name.split(<span class="string">&quot;.&quot;</span>)</span><br><span class="line">    name_pairs = [(<span class="string">&quot;.&quot;</span>.join(parts[:i]), <span class="string">&quot;.&quot;</span>.join(parts[i:])) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(parts), <span class="number">0</span>, -<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># try each alternative in turn</span></span><br><span class="line">    <span class="keyword">for</span> module_name, local_obj_name <span class="keyword">in</span> name_pairs:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            module = importlib.import_module(module_name) <span class="comment"># may raise ImportError</span></span><br><span class="line">            get_obj_from_module(module, local_obj_name) <span class="comment"># may raise AttributeError</span></span><br><span class="line">            <span class="keyword">return</span> module, local_obj_name</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># maybe some of the modules themselves contain errors?</span></span><br><span class="line">    <span class="keyword">for</span> module_name, _local_obj_name <span class="keyword">in</span> name_pairs:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            importlib.import_module(module_name) <span class="comment"># may raise ImportError</span></span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">str</span>(sys.exc_info()[<span class="number">1</span>]).startswith(<span class="string">&quot;No module named &#x27;&quot;</span> + module_name + <span class="string">&quot;&#x27;&quot;</span>):</span><br><span class="line">                <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># maybe the requested attribute is missing?</span></span><br><span class="line">    <span class="keyword">for</span> module_name, local_obj_name <span class="keyword">in</span> name_pairs:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            module = importlib.import_module(module_name) <span class="comment"># may raise ImportError</span></span><br><span class="line">            get_obj_from_module(module, local_obj_name) <span class="comment"># may raise AttributeError</span></span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># we are out of luck, but we have no idea why</span></span><br><span class="line">    <span class="keyword">raise</span> ImportError(obj_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_obj_from_module</span>(<span class="params">module: types.ModuleType, obj_name: <span class="built_in">str</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Traverses the object name and returns the last (rightmost) python object.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> obj_name == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> module</span><br><span class="line">    obj = module</span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> obj_name.split(<span class="string">&quot;.&quot;</span>):</span><br><span class="line">        obj = <span class="built_in">getattr</span>(obj, part)</span><br><span class="line">    <span class="keyword">return</span> obj</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_obj_by_name</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the python object with the given name.&quot;&quot;&quot;</span></span><br><span class="line">    module, obj_name = get_module_from_obj_name(name)</span><br><span class="line">    <span class="keyword">return</span> get_obj_from_module(module, obj_name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_func_by_name</span>(<span class="params">*args, func_name: <span class="built_in">str</span> = <span class="literal">None</span>, **kwargs</span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the python object with the given name and calls it as a function.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> func_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">    func_obj = get_obj_by_name(func_name)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">callable</span>(func_obj)</span><br><span class="line">    <span class="keyword">return</span> func_obj(*args, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">construct_class_by_name</span>(<span class="params">*args, class_name: <span class="built_in">str</span> = <span class="literal">None</span>, **kwargs</span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the python class with the given name and constructs it with the given arguments.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> call_func_by_name(*args, func_name=class_name, **kwargs)</span><br></pre></td></tr></table></figure>
<p>​    我们跟随训练集初始化的代码来看一下上述四个函数是怎么做到从字符串里“召唤”实例的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)</span><br></pre></td></tr></table></figure>
<p>​    在<code>main()</code>中注册参数的代码中，有一个<code>init_dataset_kwargs()</code>函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_dataset_kwargs</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        dataset_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;training.dataset.ImageFolderDataset&#x27;</span>, path=data, use_labels=<span class="literal">True</span>, max_size=<span class="literal">None</span>, xflip=<span class="literal">False</span>)</span><br><span class="line">        dataset_obj = dnnlib.util.construct_class_by_name(**dataset_kwargs) <span class="comment"># Subclass of training.dataset.Dataset.</span></span><br><span class="line">        dataset_kwargs.resolution = dataset_obj.resolution <span class="comment"># Be explicit about resolution.</span></span><br><span class="line">        dataset_kwargs.use_labels = dataset_obj.has_labels <span class="comment"># Be explicit about labels.</span></span><br><span class="line">        dataset_kwargs.max_size = <span class="built_in">len</span>(dataset_obj) <span class="comment"># Be explicit about dataset size.</span></span><br><span class="line">        <span class="keyword">return</span> dataset_kwargs, dataset_obj.name</span><br><span class="line">    <span class="keyword">except</span> IOError <span class="keyword">as</span> err:</span><br><span class="line">        <span class="keyword">raise</span> click.ClickException(<span class="string">f&#x27;--data: <span class="subst">&#123;err&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​    可以看看到<code>init_dataset_kwargs()</code>先整理出了一个数据集的参数，形式为字典。然后<code>construct_class_by_name()</code>接收字典解包(<code>**</code>)后的键值对。同时注意到<code>class_name</code>这个键的值为<code>&#39;training.dataset.ImageFolderDataset&#39;</code>，现在输入的键值对继续被<code>call_func_by_name()</code>调用。</p>
<p>​    在<code>call_func_by_name()</code>中，<code>&#39;training.dataset.ImageFolderDataset&#39;</code>被输入进函数<code>get_obj_by_name()</code>。在<code>get_obj_by_name()</code>中，<code>&#39;training.dataset.ImageFolderDataset&#39;</code>才被真正输入到一个实际起效的函数：<code>get_module_from_obj_name()</code>。</p>
<p>​    简而言之，在<code>get_module_from_obj_name()</code>中，输入的字符串会先按照’.’分割为一个个<code>&quot;name_pairs&quot;</code>，代表<code>module_name</code>和<code>local_obj_name</code>。例如<code>&#39;training.dataset.ImageFolderDataset&#39;</code>将会导致<code>name_pairs</code>包含：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name_pairs[0]: (&quot;training.dataset&quot;, &quot;ImageFolderDataset&quot;)</span><br><span class="line">name_pairs[1]: (&quot;training&quot;, &quot;dataset.ImageFolderDataset&quot;)</span><br><span class="line">name_pairs[2]: (&quot;&quot;, &quot;training.dataset.ImageFolderDataset&quot;)</span><br></pre></td></tr></table></figure>
<p>​    这些备选，之后函数尝试每个备选，以找到模块和对象名称正确的组合，通过<code>importlib.import_module()</code>来动态导入其他的.py文件（或者说是模块。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    module = importlib.import_module(module_name) <span class="comment"># may raise ImportError</span></span><br><span class="line">    get_obj_from_module(module, local_obj_name) <span class="comment"># may raise AttributeError</span></span><br><span class="line">    <span class="keyword">return</span> module, local_obj_name</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>​    如果找到了，就返回此时的<code>module</code>和<code>local_obj_name</code>。</p>
<p>​    所以我们现在回到了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_obj_by_name</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Finds the python object with the given name.&quot;&quot;&quot;</span></span><br><span class="line">    module, obj_name = get_module_from_obj_name(name)</span><br><span class="line">    <span class="keyword">return</span> get_obj_from_module(module, obj_name)</span><br></pre></td></tr></table></figure>
<p>​    在<code>&#39;training.dataset.ImageFolderDataset&#39;</code>这个例子下，此时的<code>module</code>就是<code>&#39;training.dataset&#39;</code>指代的python模块，<code>obj_name</code>就是<code>&#39;ImageFolderDataset&#39;</code>这个字符串。然后会通过<code>get_obj_from_module()</code>，来从<code>&#39;training.dataset&#39;</code>这个模块中，找到<code>&#39;ImageFolderDataset&#39;</code>这个类对象，最后返回。</p>
<p>​    所以<code>call_func_by_name()</code>中的<code>func_obj = get_obj_by_name(func_name)</code>，其返回值就是一个Python函数，它一般是可调用的。所以最后的<code>call_func_by_name()</code>会返回<code>func_obj(*args, **kwargs)</code>，于是就实现了动态导入并实例化我们需要的类的过程。在刚才的例子里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset_kwargs = dnnlib.EasyDict(class_name=<span class="string">&#x27;training.dataset.ImageFolderDataset&#x27;</span>, path=data, use_labels=<span class="literal">True</span>, max_size=<span class="literal">None</span>, xflip=<span class="literal">False</span>)</span><br><span class="line">dataset_obj = dnnlib.util.construct_class_by_name(**dataset_kwargs) <span class="comment"># Subclass of training.dataset.Dataset.</span></span><br></pre></td></tr></table></figure>
<p>​    实际上就等价于：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset_obj = training.dataset.ImageFolderDataset(path=data,</span><br><span class="line">                                                  use_labels=<span class="literal">True</span>,</span><br><span class="line">                                                  max_size=<span class="literal">None</span>,</span><br><span class="line">                                                  xflip=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>​    这种方式就可以避免在一些相关的.py文件开头，手动import大量模块。</p>
<h4 id="launch-training"><a href="#launch-training" class="headerlink" title="launch training"></a>launch training</h4><h5 id="DP与DDP的入门"><a href="#DP与DDP的入门" class="headerlink" title="DP与DDP的入门"></a>DP与DDP的入门</h5><p>​    按照常规的深度学习管线，配置好实验参数以后，就要开始定义一下输出目录，打log，以及写迭代用的循环体。同时由于这个项目所处理的模型，计算强度都很大，所以需要单机多卡的帮助。在main()函数的最后，我们进入了<code>launch_training()</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Launch.</span></span><br><span class="line">launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)</span><br></pre></td></tr></table></figure>
<p>​    在<code>launch_training()</code>的第一行，有一个可能由于历史原因没有被移除的logger。这个logger在这里并不会有什么实际意义，接下来<code>subprocess_fn()</code>里的logger才是真正有意义的。</p>
<p>​    <code>launch_training()</code>里接下来会定义输出目录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">launch_training</span>(<span class="params">c, desc, outdir, dry_run</span>):</span><br><span class="line">    dnnlib.util.Logger(should_flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pick output directory.</span></span><br><span class="line">    prev_run_dirs = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(outdir):</span><br><span class="line">        prev_run_dirs = [x <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(outdir) <span class="keyword">if</span> os.path.isdir(os.path.join(outdir, x))]</span><br><span class="line">    prev_run_ids = [re.match(<span class="string">r&#x27;^\d+&#x27;</span>, x) <span class="keyword">for</span> x <span class="keyword">in</span> prev_run_dirs]</span><br><span class="line">    prev_run_ids = [<span class="built_in">int</span>(x.group()) <span class="keyword">for</span> x <span class="keyword">in</span> prev_run_ids <span class="keyword">if</span> x <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">    cur_run_id = <span class="built_in">max</span>(prev_run_ids, default=-<span class="number">1</span>) + <span class="number">1</span></span><br><span class="line">    c.run_dir = os.path.join(outdir, <span class="string">f&#x27;<span class="subst">&#123;cur_run_id:05d&#125;</span>-<span class="subst">&#123;desc&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">not</span> os.path.exists(c.run_dir)</span><br></pre></td></tr></table></figure>
<p>​    输入中的<code>outdir</code>，是之前用<code>@click.command()</code>这种方式传入的保存路径，如<code>./training_runs</code>。假设<code>./training_runs</code>路径下有：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./training_runs</span><br><span class="line">    ├── 00001-desc1</span><br><span class="line">    ├── 00002-desc2</span><br><span class="line">    ├── ...</span><br><span class="line">    └── 00005-desc5</span><br></pre></td></tr></table></figure>
<p>​    那么第一个列表推导式是为了筛出<code>outdir</code>目录中所有文件和子目录中那些可以构成子目录的（即<code>00001-desc1</code>,<code>00002-desc2</code>,等）。然后用正则表达式<code>^\d+</code>匹配其中的数字，这些数字序列被<code>.group()</code>方法捕获，转换成整型，最后计算出此时应创建的实验log的序号（在之前的例子里为6）。最后与输入的<code>desc</code>拼到一起，得到<code>run_dir</code>。</p>
<p>​    然后这次训练的一般选项会记录进一个.json里，最后开始正式启动训练进程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print options.</span></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training options:&#x27;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Dataset x-flips:     <span class="subst">&#123;c.training_set_kwargs.xflip&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dry run?</span></span><br><span class="line"><span class="keyword">if</span> dry_run:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Dry run; exiting.&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create output directory.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Creating output directory...&#x27;</span>)</span><br><span class="line">os.makedirs(c.run_dir)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(c.run_dir, <span class="string">&#x27;training_options.json&#x27;</span>), <span class="string">&#x27;wt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(c, f, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch processes.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Launching processes...&#x27;</span>)</span><br><span class="line">torch.multiprocessing.set_start_method(<span class="string">&#x27;spawn&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> tempfile.TemporaryDirectory() <span class="keyword">as</span> temp_dir:</span><br><span class="line">    <span class="keyword">if</span> c.num_gpus == <span class="number">1</span>:</span><br><span class="line">        subprocess_fn(rank=<span class="number">0</span>, c=c, temp_dir=temp_dir)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        torch.multiprocessing.spawn(fn=subprocess_fn, args=(c, temp_dir), nprocs=c.num_gpus)</span><br></pre></td></tr></table></figure>
<p>​    真正执行时，EG3D采用了分布式训练。由于本科的时候没什么机会使用多卡（我只有一次在2×2080ti上用<code>nn.DataParallel()</code>的经验，但这个方式现在已经不推荐了。），所以我其实不是很熟悉多卡时的pipeline。这次正好学习一下。当GPU数量大于1时，程序会以<code>spawn</code>方法来启动多进程，具体来说，是通过<code>torch.multiprocessing.spawn()</code>启动<code>num_gpus</code>个子进程。每个子进程都会执行<code>subprocess_fn()</code>函数，同时传递相同的参数<code>c</code>和<code>temp_dir</code>。<code>temp_dir</code>是一个系统临时开的位置，用于存储不同子进程之间的通信信息。注意，如果我们只有一张卡，那么会直接调用<code>subprocess_fn()</code>，rank记为0。在多卡时，args里并没有显式输入rank，此时的rank由程序自动分配，为<code>0~c.num_gpus-1</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">subprocess_fn</span>(<span class="params">rank, c, temp_dir</span>):</span><br><span class="line">    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, <span class="string">&#x27;log.txt&#x27;</span>), file_mode=<span class="string">&#x27;a&#x27;</span>, should_flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Init torch.distributed.</span></span><br><span class="line">    <span class="keyword">if</span> c.num_gpus &gt; <span class="number">1</span>:</span><br><span class="line">        init_file = os.path.abspath(os.path.join(temp_dir, <span class="string">&#x27;.torch_distributed_init&#x27;</span>))</span><br><span class="line">        <span class="keyword">if</span> os.name == <span class="string">&#x27;nt&#x27;</span>:</span><br><span class="line">            init_method = <span class="string">&#x27;file:///&#x27;</span> + init_file.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">            torch.distributed.init_process_group(backend=<span class="string">&#x27;gloo&#x27;</span>, init_method=init_method, rank=rank, world_size=c.num_gpus)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            init_method = <span class="string">f&#x27;file://<span class="subst">&#123;init_file&#125;</span>&#x27;</span></span><br><span class="line">            torch.distributed.init_process_group(backend=<span class="string">&#x27;nccl&#x27;</span>, init_method=init_method, rank=rank, world_size=c.num_gpus)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Init torch_utils.</span></span><br><span class="line">    sync_device = torch.device(<span class="string">&#x27;cuda&#x27;</span>, rank) <span class="keyword">if</span> c.num_gpus &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)</span><br><span class="line">    <span class="keyword">if</span> rank != <span class="number">0</span>:</span><br><span class="line">        custom_ops.verbosity = <span class="string">&#x27;none&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Execute training loop.</span></span><br><span class="line">    training_loop.training_loop(rank=rank, **c)</span><br></pre></td></tr></table></figure>
<p>​    在<code>subprocess_fn()</code>开头，我们再次看到了Logger。这个Logger的实现比我之前写的要高明的多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Logger</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Redirect stderr to stdout, optionally print stdout to a file, and optionally force flushing on both stdout and the file.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, file_name: <span class="built_in">str</span> = <span class="literal">None</span>, file_mode: <span class="built_in">str</span> = <span class="string">&quot;w&quot;</span>, should_flush: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">        self.file = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> file_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.file = <span class="built_in">open</span>(file_name, file_mode)</span><br><span class="line"></span><br><span class="line">        self.should_flush = should_flush</span><br><span class="line">        self.stdout = sys.stdout</span><br><span class="line">        self.stderr = sys.stderr</span><br><span class="line"></span><br><span class="line">        sys.stdout = self</span><br><span class="line">        sys.stderr = self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__enter__</span>(<span class="params">self</span>) -&gt; <span class="string">&quot;Logger&quot;</span>:</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__exit__</span>(<span class="params">self, exc_type: <span class="type">Any</span>, exc_value: <span class="type">Any</span>, traceback: <span class="type">Any</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write</span>(<span class="params">self, text: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="built_in">bytes</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Write text to stdout (and a file) and optionally flush.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(text, <span class="built_in">bytes</span>):</span><br><span class="line">            text = text.decode()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(text) == <span class="number">0</span>: <span class="comment"># workaround for a bug in VSCode debugger: sys.stdout.write(&#x27;&#x27;); sys.stdout.flush() =&gt; crash</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.file <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.file.write(text)</span><br><span class="line"></span><br><span class="line">        self.stdout.write(text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.should_flush:</span><br><span class="line">            self.flush()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">flush</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Flush written text to both stdout and a file, if open.&quot;&quot;&quot;</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Flush, close possible files, and remove stdout/stderr mirroring.&quot;&quot;&quot;</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>​    Logger会直接将标准输出流和标准错误流重定向到自身，这样，如果Logger指定了一个可以写入的file。那么在<code>write()</code>的时候，文本就会同时写入这个file以及控制台。所以每个子进程都会有各自独立的log.txt。也就是说，任何<code>print()</code>的东西都会被记录下来。</p>
<p>​    然后会有这么几行代码来初始化多进程的环境：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Init torch.distributed.</span></span><br><span class="line"><span class="keyword">if</span> c.num_gpus &gt; <span class="number">1</span>:</span><br><span class="line">    init_file = os.path.abspath(os.path.join(temp_dir, <span class="string">&#x27;.torch_distributed_init&#x27;</span>))</span><br><span class="line">    <span class="keyword">if</span> os.name == <span class="string">&#x27;nt&#x27;</span>:</span><br><span class="line">        init_method = <span class="string">&#x27;file:///&#x27;</span> + init_file.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">        torch.distributed.init_process_group(backend=<span class="string">&#x27;gloo&#x27;</span>, init_method=init_method, rank=rank, world_size=c.num_gpus)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        init_method = <span class="string">f&#x27;file://<span class="subst">&#123;init_file&#125;</span>&#x27;</span></span><br><span class="line">        torch.distributed.init_process_group(backend=<span class="string">&#x27;nccl&#x27;</span>, init_method=init_method, rank=rank, world_size=c.num_gpus)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Init torch_utils.</span></span><br><span class="line">sync_device = torch.device(<span class="string">&#x27;cuda&#x27;</span>, rank) <span class="keyword">if</span> c.num_gpus &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)</span><br><span class="line"><span class="keyword">if</span> rank != <span class="number">0</span>:</span><br><span class="line">    custom_ops.verbosity = <span class="string">&#x27;none&#x27;</span></span><br></pre></td></tr></table></figure>
<p>​    怎么说呢，这几行代码基本就是多卡通信的API调用。由于掌握其API背后的原理和实现实在是超出了我能力范围，所以此处就不作解析了，权当咒语“咏唱”来看待吧。</p>
<blockquote>
<p>但即使我们不熟悉不同GPU通信的底层实现，我们还是可以建立一些“high level”的认识：</p>
<p>当我们在讨论并行计算时，有“模型并行”和“数据并行”两种方式。前者是说模型特别大，需要将模型拆分到多个GPU里。古早时期的AlexNet和现在的大语言模型的训练就是这个思路，但这于我而言也是“beyond reach”的存在。</p>
<p>所以我们更多的还是考虑数据并行，也就是说将数据分发给多个GPU，每个GPU保存模型的一个副本。</p>
<p>坊间传闻，这种数据并行的方案有两种。DP（DataParallel）和DDP（DistributedDataParallel），DP只允许一个进程，不同GPU的梯度汇总到GPU0（即rank=0的那块设备），然后进行反向传播来更新参数，再将参数广播到不同的GPU里。这会导致负载不均衡，因为GPU0的使用率和内存消耗会更高。</p>
<p>以及，这种实现实际是单进程多线程的训练，会受到Python中的全局解释锁（GIL）的影响。这个机制导致Python解释器一次只会执行一个线程。虽然GPU上实际进行前向和反向传播是底层库（如CUDA库）驱动的，不会受GIL的影响。但在汇总梯度和更新权重时，由于GIL的存在，一次只有一个线程可以工作，也就是其余GPU的线程会被阻塞，从而影响性能。（实际上GIL的存在其实导致了多线程的dataloader直接失效，我们熟悉的num_worker机制其实是多进程。）</p>
<p>所以在DDP中，程序开辟了不同的进程，每个进程分配独立的资源和设置（如优化器）。在各进程的梯度计算完成后，各进程将梯度汇总平均，然后再由GPU0广播到每个进程中。由于初始时刻也会将模型参数都广播一遍，所以各进程中的模型参数始终一样。由于每个进程相当于独立的程序，包含独立的解释器和全局解释锁，于是就可以绕过GIL的限制。这样就可以让负载均衡，同时并行度更高。</p>
<p>在PyTorch中，DP可以通过修改几行代码为<code>nn.DataParallel()</code>来实现。DDP就略微复杂了，PyTorch提供了<code>torch.distributed.launch()</code>和<code>torch.multiprocessing.spawn()</code>两种方式来启动。EG3D使用的是后者，也是PyTorch文档推荐的启动方法。</p>
</blockquote>
<p>​    准备工作都具备了，下面就可以开始进入训练的循环体了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">training_loop.training_loop(rank=rank, **c)</span><br></pre></td></tr></table></figure>
<p>​    （注意，这里输入的是解包后的<code>c</code>，这样在<code>training_loop()</code>的定义里就可以直接写出有哪些参数了，以增加可读性。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_loop</span>(<span class="params"></span></span><br><span class="line"><span class="params">    run_dir                 = <span class="string">&#x27;.&#x27;</span>,      <span class="comment"># Output directory.</span></span></span><br><span class="line"><span class="params">    training_set_kwargs     = &#123;&#125;,       <span class="comment"># Options for training set.</span></span></span><br><span class="line"><span class="params">    data_loader_kwargs      = &#123;&#125;,       <span class="comment"># Options for torch.utils.data.DataLoader.</span></span></span><br><span class="line"><span class="params">    G_kwargs                = &#123;&#125;,       <span class="comment"># Options for generator network.</span></span></span><br><span class="line"><span class="params">    D_kwargs                = &#123;&#125;,       <span class="comment"># Options for discriminator network.</span></span></span><br><span class="line"><span class="params">    G_opt_kwargs            = &#123;&#125;,       <span class="comment"># Options for generator optimizer.</span></span></span><br><span class="line"><span class="params">    D_opt_kwargs            = &#123;&#125;,       <span class="comment"># Options for discriminator optimizer.</span></span></span><br><span class="line"><span class="params">    ...</span></span><br><span class="line"><span class="params"></span>):</span><br></pre></td></tr></table></figure>
<h4 id="training-loop"><a href="#training-loop" class="headerlink" title="training loop"></a>training loop</h4><p>​    <code>training_loop()</code>的实现，集成了很多技术。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize.</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>, rank)</span><br><span class="line">np.random.seed(random_seed * num_gpus + rank)</span><br><span class="line">torch.manual_seed(random_seed * num_gpus + rank)</span><br><span class="line">torch.backends.cudnn.benchmark = cudnn_benchmark    <span class="comment"># Improves training speed.</span></span><br><span class="line">torch.backends.cuda.matmul.allow_tf32 = <span class="literal">False</span>       <span class="comment"># Improves numerical accuracy.</span></span><br><span class="line">torch.backends.cudnn.allow_tf32 = <span class="literal">False</span>             <span class="comment"># Improves numerical accuracy.</span></span><br><span class="line">torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = <span class="literal">False</span>  <span class="comment"># Improves numerical accuracy.</span></span><br><span class="line">conv2d_gradfix.enabled = <span class="literal">True</span>                       <span class="comment"># Improves training speed. # <span class="doctag">TODO:</span> ENABLE</span></span><br><span class="line">grid_sample_gradfix.enabled = <span class="literal">False</span>                  <span class="comment"># Avoids errors with the augmentation pipe.</span></span><br></pre></td></tr></table></figure>
<p>​    最开始的几行对torch进行了一些初始化，不是我们关心的重点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load training set.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Loading training set...&#x27;</span>)</span><br><span class="line">training_set = dnnlib.util.construct_class_by_name(**training_set_kwargs) <span class="comment"># subclass of training.dataset.Dataset</span></span><br><span class="line">training_set_sampler = misc.InfiniteSampler(dataset=training_set, rank=rank, num_replicas=num_gpus, seed=random_seed)</span><br><span class="line">training_set_iterator = <span class="built_in">iter</span>(torch.utils.data.DataLoader(dataset=training_set, sampler=training_set_sampler, batch_size=batch_size//num_gpus, **data_loader_kwargs))</span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Num images: &#x27;</span>, <span class="built_in">len</span>(training_set))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Image shape:&#x27;</span>, training_set.image_shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Label shape:&#x27;</span>, training_set.label_shape)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>
<h5 id="没用过sampler？"><a href="#没用过sampler？" class="headerlink" title="没用过sampler？"></a>没用过sampler？</h5><p>​    在构造训练集时，这里其实构造了一个比较古怪的流数据。如果读者不是很清楚dataloader，sampler，dataset这些torch里构建好的机制，可以参考<a href="https://zjwfufu.github.io/2023/09/06/PyTorch%E4%B8%AD%E7%9A%84dataloader/">这篇blog</a>。事情的古怪之处是，这个用<code>construct_class_by_name</code>构造的类，实际上是一个Map式数据集，然后这个Map数据集用一种类似Iterable的方式来<code>__getitem__</code>，为了防止多进程时，不同进程读取同一张图片以及多个进程计算了相同图片的梯度这种矛盾，它实现了一个无限循环的采样器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InfiniteSampler</span>(torch.utils.data.Sampler):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, rank=<span class="number">0</span>, num_replicas=<span class="number">1</span>, shuffle=<span class="literal">True</span>, seed=<span class="number">0</span>, window_size=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(dataset) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> num_replicas &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0</span> &lt;= rank &lt; num_replicas</span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0</span> &lt;= window_size &lt;= <span class="number">1</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(dataset)</span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.rank = rank</span><br><span class="line">        self.num_replicas = num_replicas</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.seed = seed</span><br><span class="line">        self.window_size = window_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        order = np.arange(<span class="built_in">len</span>(self.dataset))</span><br><span class="line">        rnd = <span class="literal">None</span></span><br><span class="line">        window = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            rnd = np.random.RandomState(self.seed)</span><br><span class="line">            rnd.shuffle(order)</span><br><span class="line">            window = <span class="built_in">int</span>(np.rint(order.size * self.window_size))</span><br><span class="line"></span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            i = idx % order.size</span><br><span class="line">            <span class="keyword">if</span> idx % self.num_replicas == self.rank:</span><br><span class="line">                <span class="keyword">yield</span> order[i]</span><br><span class="line">            <span class="keyword">if</span> window &gt;= <span class="number">2</span>:</span><br><span class="line">                j = (i - rnd.randint(window)) % order.size</span><br><span class="line">                order[i], order[j] = order[j], order[i]</span><br><span class="line">            idx += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>​    然后将这个sampler和刚才构造的Map式数据集，用torch的dataloader封装一次，取其迭代器。这样每次<code>next()</code>就可以得到图片和其对应的”labels”，这里的”labels”就是估计出的位姿矩阵。“labels”本身是一个1×25的向量，其前16个元素对应一个4×4的相机外参；后9个元素对应一个3×3个相机内参。如果不熟悉这里的读者可以参考这篇<a href="https://zjwfufu.github.io/2023/08/04/%E7%A5%9E%E7%BB%8F%E8%BE%90%E5%B0%84%E5%9C%BA/">NeRF的blog</a>，里面给出了相关推导。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Construct networks.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Constructing networks...&#x27;</span>)</span><br><span class="line">common_kwargs = <span class="built_in">dict</span>(c_dim=training_set.label_dim, img_resolution=training_set.resolution, img_channels=training_set.num_channels)</span><br><span class="line">G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(<span class="literal">False</span>).to(device) <span class="comment"># subclass of torch.nn.Module</span></span><br><span class="line">G.register_buffer(<span class="string">&#x27;dataset_label_std&#x27;</span>, torch.tensor(training_set.get_label_std()).to(device))</span><br><span class="line">D = dnnlib.util.construct_class_by_name(**D_kwargs, **common_kwargs).train().requires_grad_(<span class="literal">False</span>).to(device) <span class="comment"># subclass of torch.nn.Module</span></span><br><span class="line">G_ema = copy.deepcopy(G).<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<p>​    然后接下来就开始构造网络本身了，在EG3D中，这里具体构造的是哪个网络由<code>train.py</code>的267~268行给出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c.G_kwargs.class_name = <span class="string">&#x27;training.triplane.TriPlaneGenerator&#x27;</span></span><br><span class="line">c.D_kwargs.class_name = <span class="string">&#x27;training.dual_discriminator.DualDiscriminator&#x27;</span></span><br></pre></td></tr></table></figure>
<p>​    稍后我们具体分析其计算过程时，要去找对应的类实现。</p>
<h5 id="“持久化”的用处"><a href="#“持久化”的用处" class="headerlink" title="“持久化”的用处"></a>“持久化”的用处</h5><p>​    然后是几行非常巧妙的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Resume from existing pickle.</span></span><br><span class="line"><span class="keyword">if</span> (resume_pkl <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (rank == <span class="number">0</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Resuming from &quot;<span class="subst">&#123;resume_pkl&#125;</span>&quot;&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> dnnlib.util.open_url(resume_pkl) <span class="keyword">as</span> f:</span><br><span class="line">        resume_data = legacy.load_network_pkl(f)</span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> [(<span class="string">&#x27;G&#x27;</span>, G), (<span class="string">&#x27;D&#x27;</span>, D), (<span class="string">&#x27;G_ema&#x27;</span>, G_ema)]:</span><br><span class="line">        misc.copy_params_and_buffers(resume_data[name], module, require_all=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>​    可能有人会疑惑：“这不就是读了个pkl么？有什么巧妙的。”，实际上巧妙的原因并不是因为读取保存格式为.pkl的checkpoints。是因为在EG3D的代码库里，每一个神经网络（继承自<code>torch.nn.Module</code>）的任何类，实现时都被这么一个装饰器装饰了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@persistence.persistent_class</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TriPlaneGenerator</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,...</span>)</span><br></pre></td></tr></table></figure>
<p>​    这个装饰器函数意为“持久化”，其定义是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">persistent_class</span>(<span class="params">orig_class</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(orig_class, <span class="built_in">type</span>)</span><br><span class="line">    <span class="keyword">if</span> is_persistent(orig_class):</span><br><span class="line">        <span class="keyword">return</span> orig_class</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> orig_class.__module__ <span class="keyword">in</span> sys.modules</span><br><span class="line">    orig_module = sys.modules[orig_class.__module__]</span><br><span class="line">    orig_module_src = _module_to_src(orig_module)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Decorator</span>(<span class="title class_ inherited__">orig_class</span>):</span><br><span class="line">        _orig_module_src = orig_module_src</span><br><span class="line">        _orig_class_name = orig_class.__name__</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">            <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line">            self._init_args = copy.deepcopy(args)</span><br><span class="line">            self._init_kwargs = copy.deepcopy(kwargs)</span><br><span class="line">            <span class="keyword">assert</span> orig_class.__name__ <span class="keyword">in</span> orig_module.__dict__</span><br><span class="line">            _check_pickleable(self.__reduce__())</span><br><span class="line"></span><br><span class="line"><span class="meta">        @property</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">init_args</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> copy.deepcopy(self._init_args)</span><br><span class="line"></span><br><span class="line"><span class="meta">        @property</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">init_kwargs</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> dnnlib.EasyDict(copy.deepcopy(self._init_kwargs))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__reduce__</span>(<span class="params">self</span>):</span><br><span class="line">            fields = <span class="built_in">list</span>(<span class="built_in">super</span>().__reduce__())</span><br><span class="line">            fields += [<span class="literal">None</span>] * <span class="built_in">max</span>(<span class="number">3</span> - <span class="built_in">len</span>(fields), <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> fields[<span class="number">0</span>] <span class="keyword">is</span> <span class="keyword">not</span> _reconstruct_persistent_obj:</span><br><span class="line">                meta = <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;class&#x27;</span>, version=_version, module_src=self._orig_module_src, class_name=self._orig_class_name, state=fields[<span class="number">2</span>])</span><br><span class="line">                fields[<span class="number">0</span>] = _reconstruct_persistent_obj <span class="comment"># reconstruct func</span></span><br><span class="line">                fields[<span class="number">1</span>] = (meta,) <span class="comment"># reconstruct args</span></span><br><span class="line">                fields[<span class="number">2</span>] = <span class="literal">None</span> <span class="comment"># state dict</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">tuple</span>(fields)</span><br><span class="line"></span><br><span class="line">    Decorator.__name__ = orig_class.__name__</span><br><span class="line">    _decorators.add(Decorator)</span><br><span class="line">    <span class="keyword">return</span> Decorator</span><br></pre></td></tr></table></figure>
<p>​    这个装饰器将会巧妙的利用Python中的<code>pickle</code>模块，完成一个很有意思的功能。我们先关注这个装饰器的实现，它会传入一个类，比如一个定义好的神经网络类，然后返回一个Decorator类。这个Decorator类继承自原来的类，并且有一些新的属性和方法，特别是其中的<code>__reduce__</code>，这是Python专门给pickle模块预留的一个魔法方法，用来规定反序列化时的规则。是Python用来给用户提供一个复原相对复杂的object的方式。如<code>__reduce__</code>所示，其最后会返回一个tuple，元组的第一位是“<code>_reconstruct_persistent_obj</code>”，代表<code>__reduce__</code>会使用这种方式来复原这个object。第二位是所需要的参数，在这里是<code>meta</code>。</p>
<p>​    那么这个装饰器具体做了什么呢？我们从头来看。当我们传入一个类<code>orig_class</code>时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">orig_module = sys.modules[orig_class.__module__]</span><br><span class="line">orig_module_src = _module_to_src(orig_module)</span><br></pre></td></tr></table></figure>
<p>​    <code>orig_class.__module__</code>是这个类所在模块的字符串，<code>sys.modules</code>是Python基础库提供的一个字典，其键为模块名，值为模块对象。所以<code>orig_module</code>被赋值为<code>orig_class</code>所在的模块，然后<code>_module_to_src()</code>函数会利用inspect库返回此时这个模块的源代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_module_to_src</span>(<span class="params">module</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Query the source code of a given Python module.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    src = _module_to_src_dict.get(module, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> src <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        src = inspect.getsource(module)</span><br><span class="line">        _module_to_src_dict[module] = src</span><br><span class="line">        _src_to_module_dict[src] = module</span><br><span class="line">    <span class="keyword">return</span> src</span><br></pre></td></tr></table></figure>
<p>​    这个源代码<code>orig_module_src</code>最后会写入Decorator类里，作为类内成员，最后在调用<code>__reduce__</code>时用在<code>meta</code>这个字典里。所以当我们反序列化时，会使用这个自定义的<code>__reduce__</code>方法，调用<code>_reconstruct_persistent_obj(meta)</code>。重建的这个函数为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_reconstruct_persistent_obj</span>(<span class="params">meta</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Hook that is called internally by the `pickle` module to unpickle</span></span><br><span class="line"><span class="string">    a persistent object.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    meta = dnnlib.EasyDict(meta)</span><br><span class="line">    meta.state = dnnlib.EasyDict(meta.state)</span><br><span class="line">    <span class="keyword">for</span> hook <span class="keyword">in</span> _import_hooks:</span><br><span class="line">        meta = hook(meta)</span><br><span class="line">        <span class="keyword">assert</span> meta <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> meta.version == _version</span><br><span class="line">    module = _src_to_module(meta.module_src)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> meta.<span class="built_in">type</span> == <span class="string">&#x27;class&#x27;</span></span><br><span class="line">    orig_class = module.__dict__[meta.class_name]</span><br><span class="line">    decorator_class = persistent_class(orig_class)</span><br><span class="line">    obj = decorator_class.__new__(decorator_class)</span><br><span class="line"></span><br><span class="line">    setstate = <span class="built_in">getattr</span>(obj, <span class="string">&#x27;__setstate__&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">callable</span>(setstate):</span><br><span class="line">        setstate(meta.state) <span class="comment"># pylint: disable=not-callable</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        obj.__dict__.update(meta.state)</span><br><span class="line">    <span class="keyword">return</span> obj</span><br></pre></td></tr></table></figure>
<p>​    这里面的关键在于<code>_src_to_module()</code>函数，其从此时模块的源代码中复原这个模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_src_to_module</span>(<span class="params">src</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Get or create a Python module for the given source code.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    module = _src_to_module_dict.get(src, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> module <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        module_name = <span class="string">&quot;_imported_module_&quot;</span> + uuid.uuid4().<span class="built_in">hex</span></span><br><span class="line">        module = types.ModuleType(module_name)</span><br><span class="line">        sys.modules[module_name] = module</span><br><span class="line">        _module_to_src_dict[module] = src</span><br><span class="line">        _src_to_module_dict[src] = module</span><br><span class="line">        <span class="built_in">exec</span>(src, module.__dict__) <span class="comment"># pylint: disable=exec-used</span></span><br><span class="line">    <span class="keyword">return</span> module</span><br></pre></td></tr></table></figure>
<p>​    此时会将一个不可能重复的<code>module_name</code>强制转换为<code>ModuleType</code>类型的<code>module</code>，作为<code>sys.module</code>的键，最后用<code>exec()</code>执行给定的源代码，将其加载到新创建的模块<code>module</code>里，最后返回<code>module</code>。</p>
<p>​    得到了此时的<code>module</code>以后，<code>meta</code>里还存放着需要还原的类的<code>class_name</code>，于是通过查询<code>module.__dict__</code>即可复原这个<code>orig_class</code>。</p>
<p>​    我们跳到<code>training_loop.py</code>中的第394行~409行，我们可以发现程序逻辑上会将<code>training_set_kwargs</code>和<code>[(&#39;G&#39;, G), (&#39;D&#39;, D), (&#39;G_ema&#39;, G_ema), (&#39;augment_pipe&#39;, augment_pipe)]</code>都dump进.pkl文件中。所以再读取这个.pkl时，就会按照写入这个.pkl时的各种类的实现，来复原此时的<code>G</code>,<code>D</code>等对象。</p>
<p>​    所以，假设此时我们正在开发一个炼丹项目，我们按照上述逻辑运行，得到了一个.pkl的存根。过了几天，我们可能修改了这个项目里，例如GAN中生成器的结构，不管是输入参数还是网络结构本身。此时我们读入这个pkl，往往会得到matching error的报错。但由于刚才的Decorator类，其类中记录了之前这个网络的所有定义（包括输入参数，源代码等），新的<code>__reduce__</code>所返回的tuple，是按照之前Decorator继承来的父类（即原来的模型）来的，所以这就可以让我们在不修改当前代码的情况下，直接读取在开发过程中版本不相同的checkpoints。</p>
<h5 id="构造循环体"><a href="#构造循环体" class="headerlink" title="构造循环体"></a>构造循环体</h5><p>​    然后的代码负责记录了一下此时的网络结构，打印进log里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print network summary tables.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    z = torch.empty([batch_gpu, G.z_dim], device=device)</span><br><span class="line">    c = torch.empty([batch_gpu, G.c_dim], device=device)</span><br><span class="line">    img = misc.print_module_summary(G, [z, c])</span><br><span class="line">    misc.print_module_summary(D, [img, c])</span><br></pre></td></tr></table></figure>
<p>​    这里用到的misc中的<code>print_module_summary()</code>是一个自行编写的函数，其中用到了torch中的hook机制来捕获各个子模块的参数量和输入输出形状等信息，其实就是Kera里model.summary()的平替。</p>
<blockquote>
<p>实际上，后来一个非官方的包torchsummary也可以做到这一点了。</p>
</blockquote>
<p>​    然后又是设置一个数据增强的管线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup augmentation.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Setting up augmentation...&#x27;</span>)</span><br><span class="line">augment_pipe = <span class="literal">None</span></span><br><span class="line">ada_stats = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> (augment_kwargs <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (augment_p &gt; <span class="number">0</span> <span class="keyword">or</span> ada_target <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">    augment_pipe = dnnlib.util.construct_class_by_name(**augment_kwargs).train().requires_grad_(<span class="literal">False</span>).to(device) <span class="comment"># subclass of torch.nn.Module</span></span><br><span class="line">    augment_pipe.p.copy_(torch.as_tensor(augment_p))</span><br><span class="line">    <span class="keyword">if</span> ada_target <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        ada_stats = training_stats.Collector(regex=<span class="string">&#x27;Loss/signs/real&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​    这个管线其实是来自于<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.06676">这篇论文</a>，也是nVidia的工作，简单来说就是教我们如何给GAN做数据增强（想象一下，我们好像不能那么鲁莽的将一些augmentation推广到GAN的训练中，比如翻转，这会导致网络生成翻转后的图像）。所以这里就实现了一种自适应机制的augmentation。这里就不展开了。</p>
<p>​    一般来说，在一些别的任务里，我们一般会把aug放在dataset的实现里，例如在<code>__getitem__</code>里写一些分支判断。但在这里，如上面代码注释所示，这里的<code>augment_pipe</code>实际上也是一个继承自<code>torch.nn.Module</code>的，一旦调用它会自动运行<code>forward</code>方法。这个增强管线实际上会在loss类中的<code>run_D()</code>里被调用，然后大显神威。</p>
<p>​    然后下面的这段代码块会将此时模型的参数（不管是随机初始化的还是从resume里读进来的）都广播到各个进程中，保证参数最开始都一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Distribute across GPUs.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Distributing across <span class="subst">&#123;num_gpus&#125;</span> GPUs...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> [G, D, G_ema, augment_pipe]:</span><br><span class="line">    <span class="keyword">if</span> module <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> misc.params_and_buffers(module):</span><br><span class="line">            <span class="keyword">if</span> param.numel() &gt; <span class="number">0</span> <span class="keyword">and</span> num_gpus &gt; <span class="number">1</span>:</span><br><span class="line">                torch.distributed.broadcast(param, src=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>​    然后接下来，是确定训练过程的一个settings。实际上是对训练GAN的一个封装。在我们刚接触GAN时，我们往往会实现这样的伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(cfg.epochs):</span><br><span class="line">	<span class="keyword">for</span> i, (imgs, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        real_label = torch.ones(imgs.size(<span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">        fake_label = torch.zeros(imgs.size(<span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#	Train Discriminator</span></span><br><span class="line">        real_output = D(imgs)</span><br><span class="line">        d_loss_real = criterion(real_output, real_label)</span><br><span class="line">        </span><br><span class="line">        z = torch.randn(imgs.size(<span class="number">0</span>), dim_z)</span><br><span class="line">        fake_imgs = G(z).detach()</span><br><span class="line">        fake_output = D(fake_imgs)</span><br><span class="line">        d_loss_fake = criterion(fake_output, fake_label)</span><br><span class="line">        </span><br><span class="line">        d_loss = d_loss_real + d_loss_fake</span><br><span class="line">        d_opt.zero_grad()</span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_opt.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#	Train Generator</span></span><br><span class="line">        z = torch.randn(imgs.size(<span class="number">0</span>), dim_z)</span><br><span class="line">        fake_imgs = G(z)</span><br><span class="line">        output = D(fake_imgs)</span><br><span class="line">        g_loss = criterion(output, real_label)</span><br><span class="line">        </span><br><span class="line">        g_opt.zero_grad()</span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_opt.step()</span><br></pre></td></tr></table></figure>
<p>​    这样即可实现“交错”的训练生成器和判别器，然后有时候，由于训练判别器比训练生成器容易的多，所以可能我们会进一步在上面的代码里加个判断分支，例如每$k$个mini-batches再训练一次判别器。在EG3D的代码里，对其进行了更“厚实”的封装。</p>
<p>​    具体来说，在<code>training_loop</code>里，我们只会看见一个可迭代对象“phase”，以及“loss”的设置。loss一般是继承自基类<code>Loss</code>的<code>StyleGAN2Loss</code>，其有<code>run_G</code>，<code>run_D</code>，<code>accumulate_gradients</code>方法。在<code>accumulate_gradients</code>中实现了loss每一项的具体计算。而上一层级里的“phase”是来确定<code>accumulate_gradients</code>方法里计算哪些项的。例如对于生成器，我们计算<code>G_main</code>，根据此时的批次，我们考虑是否计算<code>G_reg</code>；对于判别器，我们考虑计算<code>D_main</code>，<code>D_r1</code>等。</p>
<p>​    我们先继续走完<code>training_loop</code>的流程，然后就能切洋葱切到EG3D的计算过程了。所以不要心急。如上文所示，我们会将训练生成器，判别器时的配置，都打包成一个字典，作为一个列表的元素。如果没有正则化（至于这个正则化具体是什么，我们先按下不表），那么phase里可能只会有<code>Gboth</code>，<code>Dboth</code>，也就是长度为2的列表。根据有没有正则化的设定，最多会有四个字典作为列表元素，即<code>Gmain</code>，<code>Greg</code>，<code>Dmain</code>，<code>Dreg</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup training phases.</span></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Setting up training phases...&#x27;</span>)</span><br><span class="line">loss = dnnlib.util.construct_class_by_name(device=device, G=G, D=D, augment_pipe=augment_pipe, **loss_kwargs) <span class="comment"># subclass of training.loss.Loss</span></span><br><span class="line">phases = []</span><br><span class="line"><span class="keyword">for</span> name, module, opt_kwargs, reg_interval <span class="keyword">in</span> [(<span class="string">&#x27;G&#x27;</span>, G, G_opt_kwargs, G_reg_interval), (<span class="string">&#x27;D&#x27;</span>, D, D_opt_kwargs, D_reg_interval)]:</span><br><span class="line">    <span class="keyword">if</span> reg_interval <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        opt = dnnlib.util.construct_class_by_name(params=module.parameters(), **opt_kwargs) <span class="comment"># subclass of torch.optim.Optimizer</span></span><br><span class="line">        phases += [dnnlib.EasyDict(name=name+<span class="string">&#x27;both&#x27;</span>, module=module, opt=opt, interval=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># Lazy regularization.</span></span><br><span class="line">        mb_ratio = reg_interval / (reg_interval + <span class="number">1</span>)</span><br><span class="line">        opt_kwargs = dnnlib.EasyDict(opt_kwargs)</span><br><span class="line">        opt_kwargs.lr = opt_kwargs.lr * mb_ratio</span><br><span class="line">        opt_kwargs.betas = [beta ** mb_ratio <span class="keyword">for</span> beta <span class="keyword">in</span> opt_kwargs.betas]</span><br><span class="line">        opt = dnnlib.util.construct_class_by_name(module.parameters(), **opt_kwargs) <span class="comment"># subclass of torch.optim.Optimizer</span></span><br><span class="line">        phases += [dnnlib.EasyDict(name=name+<span class="string">&#x27;main&#x27;</span>, module=module, opt=opt, interval=<span class="number">1</span>)]</span><br><span class="line">        phases += [dnnlib.EasyDict(name=name+<span class="string">&#x27;reg&#x27;</span>, module=module, opt=opt, interval=reg_interval)]</span><br><span class="line"><span class="keyword">for</span> phase <span class="keyword">in</span> phases:</span><br><span class="line">    phase.start_event = <span class="literal">None</span></span><br><span class="line">    phase.end_event = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">        phase.start_event = torch.cuda.Event(enable_timing=<span class="literal">True</span>)</span><br><span class="line">        phase.end_event = torch.cuda.Event(enable_timing=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​    然后，进入第260行的<code>while True</code>循环，就可以发现训练的核心部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fetch training data.</span></span><br><span class="line"><span class="keyword">with</span> torch.autograd.profiler.record_function(<span class="string">&#x27;data_fetch&#x27;</span>):</span><br><span class="line">    phase_real_img, phase_real_c = <span class="built_in">next</span>(training_set_iterator)</span><br><span class="line">    phase_real_img = (phase_real_img.to(device).to(torch.float32) / <span class="number">127.5</span> - <span class="number">1</span>).split(batch_gpu)</span><br><span class="line">    phase_real_c = phase_real_c.to(device).split(batch_gpu)</span><br><span class="line">    all_gen_z = torch.randn([<span class="built_in">len</span>(phases) * batch_size, G.z_dim], device=device)</span><br><span class="line">    all_gen_z = [phase_gen_z.split(batch_gpu) <span class="keyword">for</span> phase_gen_z <span class="keyword">in</span> all_gen_z.split(batch_size)]</span><br><span class="line">    all_gen_c = [training_set.get_label(np.random.randint(<span class="built_in">len</span>(training_set))) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(phases) * batch_size)]</span><br><span class="line">    all_gen_c = torch.from_numpy(np.stack(all_gen_c)).pin_memory().to(device)</span><br><span class="line">    all_gen_c = [phase_gen_c.split(batch_gpu) <span class="keyword">for</span> phase_gen_c <span class="keyword">in</span> all_gen_c.split(batch_size)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> phase, phase_gen_z, phase_gen_c <span class="keyword">in</span> <span class="built_in">zip</span>(phases, all_gen_z, all_gen_c):</span><br><span class="line">    <span class="keyword">if</span> batch_idx % phase.interval != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> phase.start_event <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        phase.start_event.record(torch.cuda.current_stream(device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Accumulate gradients.</span></span><br><span class="line">    phase.opt.zero_grad(set_to_none=<span class="literal">True</span>)</span><br><span class="line">    phase.module.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> real_img, real_c, gen_z, gen_c <span class="keyword">in</span> <span class="built_in">zip</span>(phase_real_img, phase_real_c, phase_gen_z, phase_gen_c):</span><br><span class="line">        loss.accumulate_gradients(phase=phase.name, real_img=real_img, real_c=real_c, gen_z=gen_z, gen_c=gen_c, gain=phase.interval, cur_nimg=cur_nimg)</span><br><span class="line">    phase.module.requires_grad_(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights.</span></span><br><span class="line">    <span class="keyword">with</span> torch.autograd.profiler.record_function(phase.name + <span class="string">&#x27;_opt&#x27;</span>):</span><br><span class="line">        params = [param <span class="keyword">for</span> param <span class="keyword">in</span> phase.module.parameters() <span class="keyword">if</span> param.numel() &gt; <span class="number">0</span> <span class="keyword">and</span> param.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(params) &gt; <span class="number">0</span>:</span><br><span class="line">            flat = torch.cat([param.grad.flatten() <span class="keyword">for</span> param <span class="keyword">in</span> params])</span><br><span class="line">            <span class="keyword">if</span> num_gpus &gt; <span class="number">1</span>:</span><br><span class="line">                torch.distributed.all_reduce(flat)</span><br><span class="line">                flat /= num_gpus</span><br><span class="line">            misc.nan_to_num(flat, nan=<span class="number">0</span>, posinf=<span class="number">1e5</span>, neginf=-<span class="number">1e5</span>, out=flat)</span><br><span class="line">            grads = flat.split([param.numel() <span class="keyword">for</span> param <span class="keyword">in</span> params])</span><br><span class="line">                <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>(params, grads):</span><br><span class="line">                    param.grad = grad.reshape(param.shape)</span><br><span class="line">        phase.opt.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Phase done.</span></span><br><span class="line">        <span class="keyword">if</span> phase.end_event <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            phase.end_event.record(torch.cuda.current_stream(device))</span><br></pre></td></tr></table></figure>
<p>​    首先先砍瓜切菜从数据集里拿图片<code>phase_real_img</code>和相机位姿<code>phase_real_c</code>（这里的c既可以理解为condition）。然后图像被缩放到[-1, 1]，分成<code>batch_gpu</code>批（<code>phase_real_c</code>也是分成<code>batch_gpu</code>批）。这里<code>batch_gpu</code>就是一块gpu同时计算的数量，可以理解为单卡时的batchsize，只不过此时真正的batchsize一般会是<code>batch_gpu * num_gpus</code>个。这里用的是<code>split()</code>方法，也就是其被分成若干子批次的列表。</p>
<p>​    然后GAN采样用的随机变量<code>all_gen_z</code>和<code>all_gen_c</code>被创建，注意他们在创建时都需要满足最后的列表长度与phases一致，这样就可以后面用<code>zip</code>来合并了。例如假设<code>all_gen_z</code>是大小为[4 * 32, 100]的张量，其中4是phases的长度，32是batchsize。</p>
<p>​    然后<code>all_gen_z</code>的列表推导式的意思是：从<code>all_gen_z.split(batch_size)</code>中进行遍历，遍历得到的每个列表元素为大小为[32, 100]的张量。此时列表的长度为4，同时会对在这个返回列表里的张量元素再作<code>split(batch_gpu)</code>，这样长度为4的列表的每个元素，就是长度也为batch_size/batch_gpu的子列表了。<code>all_gen_c</code>道理也是一样的。</p>
<p>​    然后我们发现phases（长度为4的列表）和<code>all_gen_z</code>，<code>all_gen_c</code>会一起遍历。phases遍历的元素phase自然是之前讨论的不同的训练阶段，如<code>Gmain</code>，<code>Dreg</code>。<code>phase_gen_z</code>和<code>phase_gen_c</code>会是刚才说的“列表元素中被切分的张量所形成的子列表”。所以在计算loss的时候，又嵌套了一层for循环+zip，作为loss计算时传入的参数。backward被封装进了<code>loss.accumulate_gradients</code>里了，所以接下来就是根据梯度来更新权重。</p>
<blockquote>
<p>细心的话可以注意到第158行，160行，即生成器G和判别器D一开始就是requires_grad_(False)的，也就是说一开始就不会计算梯度。而只有到了第282行~285行要计算梯度时，才会把这个阶段对应的module（生成器或判别器）的梯度追踪标志打开，这样可以减少不必要的内存和显存开销。</p>
</blockquote>
<p>​    在更新权重的那个部分，我们可以发现，和我们在DP与DDP部分说的一样，程序使用<code>torch.distributed.all_reduce()</code>来进行梯度同步，将平均后的梯度赋值给此进程下的模型参数（里的梯度）。</p>
<blockquote>
<p>注意，赋值的那个for循环，更新的其实是param中的grad。param其实是一个列表生成式产生的列表，它并不是phase.module.parameters()的复制，而仅仅是一个引用。</p>
</blockquote>
<p>​    <code>while True</code>的剩下的部分，执行的就是一些常规的操作了，基本就是更新一些训练时的计数器啊之类的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Update G_ema.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update state.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Execute ADA heuristic.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Perform maintenance tasks once per tick.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print status line, accumulating the same information in training_stats.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check for abort.</span></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">not</span> done) <span class="keyword">and</span> (abort_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> abort_fn():</span><br><span class="line">    done = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Aborting...&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save image snapshot.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save network snapshot.</span></span><br><span class="line">snapshot_pkl = <span class="literal">None</span></span><br><span class="line">snapshot_data = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> (network_snapshot_ticks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (done <span class="keyword">or</span> cur_tick % network_snapshot_ticks == <span class="number">0</span>):</span><br><span class="line">    snapshot_data = <span class="built_in">dict</span>(training_set_kwargs=<span class="built_in">dict</span>(training_set_kwargs))</span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> [(<span class="string">&#x27;G&#x27;</span>, G), (<span class="string">&#x27;D&#x27;</span>, D), (<span class="string">&#x27;G_ema&#x27;</span>, G_ema), (<span class="string">&#x27;augment_pipe&#x27;</span>, augment_pipe)]:</span><br><span class="line">        <span class="keyword">if</span> module <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> num_gpus &gt; <span class="number">1</span>:</span><br><span class="line">                misc.check_ddp_consistency(module, ignore_regex=<span class="string">r&#x27;.*\.[^.]+_(avg|ema)&#x27;</span>)</span><br><span class="line">            module = copy.deepcopy(module).<span class="built_in">eval</span>().requires_grad_(<span class="literal">False</span>).cpu()</span><br><span class="line">        snapshot_data[name] = module</span><br><span class="line">        <span class="keyword">del</span> module <span class="comment"># conserve memory</span></span><br><span class="line">    snapshot_pkl = os.path.join(run_dir, <span class="string">f&#x27;network-snapshot-<span class="subst">&#123;cur_nimg//<span class="number">1000</span>:06d&#125;</span>.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(snapshot_pkl, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            pickle.dump(snapshot_data, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate metrics.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Collect statistics.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update logs.</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update state.</span></span><br><span class="line">cur_tick += <span class="number">1</span></span><br><span class="line">tick_start_nimg = cur_nimg</span><br><span class="line">tick_start_time = time.time()</span><br><span class="line">maintenance_time = tick_start_time - tick_end_time</span><br><span class="line"><span class="keyword">if</span> done:</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>​    所以我们发现，所有的计算过程，比如用了哪些loss（约束），都打包进了<code>loss.accumulate_gradients</code>，下面我们来看一下这个<code>accumulate_gradients()</code>函数。</p>
<h4 id="accumulate-gradients"><a href="#accumulate-gradients" class="headerlink" title="accumulate gradients"></a>accumulate gradients</h4><p>​    在解释这个部分之前，我们需要形式化的认识一些GAN的损失函数。因为EG3D其实是styleGAN2的直接应用，而styleGAN2已经是一个非常成熟的GAN了，里面有些事情我们可能并不知道。在loss.py中，我们可以看到这样的代码结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StyleGAN2Loss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device, G, D, augment_pipe=<span class="literal">None</span>, r1_gamma=<span class="number">10</span>, style_mixing_prob=<span class="number">0</span>, pl_weight=<span class="number">0</span>, pl_batch_shrink=<span class="number">2</span>, pl_decay=<span class="number">0.01</span>, pl_no_weight_grad=<span class="literal">False</span>, blur_init_sigma=<span class="number">0</span>, blur_fade_kimg=<span class="number">0</span>, r1_gamma_init=<span class="number">0</span>, r1_gamma_fade_kimg=<span class="number">0</span>, neural_rendering_resolution_initial=<span class="number">64</span>, neural_rendering_resolution_final=<span class="literal">None</span>, neural_rendering_resolution_fade_kimg=<span class="number">0</span>, gpc_reg_fade_kimg=<span class="number">1000</span>, gpc_reg_prob=<span class="literal">None</span>, dual_discrimination=<span class="literal">False</span>, filter_mode=<span class="string">&#x27;antialiased&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.device             = device</span><br><span class="line">        self.G                  = G</span><br><span class="line">        self.D                  = D</span><br><span class="line">        self.augment_pipe       = augment_pipe</span><br><span class="line">        self.r1_gamma           = r1_gamma</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">assert</span> self.gpc_reg_prob <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> (<span class="number">0</span> &lt;= self.gpc_reg_prob &lt;= <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run_G</span>(<span class="params">self, z, c, swapping_prob, neural_rendering_resolution, update_emas=<span class="literal">False</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">return</span> gen_output, ws</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run_D</span>(<span class="params">self, img, c, blur_sigma=<span class="number">0</span>, blur_sigma_raw=<span class="number">0</span>, update_emas=<span class="literal">False</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accumulate_gradients</span>(<span class="params">self, phase, real_img, real_c, gen_z, gen_c, gain, cur_nimg</span>):</span><br><span class="line">        <span class="keyword">assert</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Gmain&#x27;</span>, <span class="string">&#x27;Greg&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>, <span class="string">&#x27;Dmain&#x27;</span>, <span class="string">&#x27;Dreg&#x27;</span>, <span class="string">&#x27;Dboth&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> self.G.rendering_kwargs.get(<span class="string">&#x27;density_reg&#x27;</span>, <span class="number">0</span>) == <span class="number">0</span>:</span><br><span class="line">            phase = &#123;<span class="string">&#x27;Greg&#x27;</span>: <span class="string">&#x27;none&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>: <span class="string">&#x27;Gmain&#x27;</span>&#125;.get(phase, phase)</span><br><span class="line">        <span class="keyword">if</span> self.r1_gamma == <span class="number">0</span>:</span><br><span class="line">            phase = &#123;<span class="string">&#x27;Dreg&#x27;</span>: <span class="string">&#x27;none&#x27;</span>, <span class="string">&#x27;Dboth&#x27;</span>: <span class="string">&#x27;Dmain&#x27;</span>&#125;.get(phase, phase)</span><br><span class="line">        blur_sigma = <span class="built_in">max</span>(<span class="number">1</span> - cur_nimg / (self.blur_fade_kimg * <span class="number">1e3</span>), <span class="number">0</span>) * self.blur_init_sigma <span class="keyword">if</span> self.blur_fade_kimg &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        r1_gamma = self.r1_gamma</span><br><span class="line"></span><br><span class="line">        alpha = <span class="built_in">min</span>(cur_nimg / (self.gpc_reg_fade_kimg * <span class="number">1e3</span>), <span class="number">1</span>) <span class="keyword">if</span> self.gpc_reg_fade_kimg &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        swapping_prob = (<span class="number">1</span> - alpha) * <span class="number">1</span> + alpha * self.gpc_reg_prob <span class="keyword">if</span> self.gpc_reg_prob <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.neural_rendering_resolution_final <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            alpha = <span class="built_in">min</span>(cur_nimg / (self.neural_rendering_resolution_fade_kimg * <span class="number">1e3</span>), <span class="number">1</span>)</span><br><span class="line">            neural_rendering_resolution = <span class="built_in">int</span>(np.rint(self.neural_rendering_resolution_initial * (<span class="number">1</span> - alpha) + self.neural_rendering_resolution_final * alpha))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            neural_rendering_resolution = self.neural_rendering_resolution_initial</span><br><span class="line"></span><br><span class="line">        real_img_raw = filtered_resizing(real_img, size=neural_rendering_resolution, f=self.resample_filter, filter_mode=self.filter_mode)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.blur_raw_target:</span><br><span class="line">            blur_size = np.floor(blur_sigma * <span class="number">3</span>)</span><br><span class="line">            <span class="keyword">if</span> blur_size &gt; <span class="number">0</span>:</span><br><span class="line">                f = torch.arange(-blur_size, blur_size + <span class="number">1</span>, device=real_img_raw.device).div(blur_sigma).square().neg().exp2()</span><br><span class="line">                real_img_raw = upfirdn2d.filter2d(real_img_raw, f / f.<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">        real_img = &#123;<span class="string">&#x27;image&#x27;</span>: real_img, <span class="string">&#x27;image_raw&#x27;</span>: real_img_raw&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Gmain: Maximize logits for generated images.</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Gmain&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>]:</span><br><span class="line">            ...</span><br><span class="line">            loss_Gmain.mean().mul(gain).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Density Regularization</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Greg&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>] <span class="keyword">and</span> self.G.rendering_kwargs.get(<span class="string">&#x27;density_reg&#x27;</span>, <span class="number">0</span>) &gt; <span class="number">0</span> <span class="keyword">and</span> self.G.rendering_kwargs[<span class="string">&#x27;reg_type&#x27;</span>] == <span class="string">&#x27;l1&#x27;</span>:</span><br><span class="line">            ...</span><br><span class="line">            TVloss = torch.nn.functional.l1_loss(sigma_initial, sigma_perturbed) * self.G.rendering_kwargs[<span class="string">&#x27;density_reg&#x27;</span>]</span><br><span class="line">            TVloss.mul(gain).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Alternative density regularization</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Greg&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>] <span class="keyword">and</span> self.G.rendering_kwargs.get(<span class="string">&#x27;density_reg&#x27;</span>, <span class="number">0</span>) &gt; <span class="number">0</span> <span class="keyword">and</span> self.G.rendering_kwargs[<span class="string">&#x27;reg_type&#x27;</span>] == <span class="string">&#x27;monotonic-detach&#x27;</span>:</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Alternative density regularization</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Greg&#x27;</span>, <span class="string">&#x27;Gboth&#x27;</span>] <span class="keyword">and</span> self.G.rendering_kwargs.get(<span class="string">&#x27;density_reg&#x27;</span>, <span class="number">0</span>) &gt; <span class="number">0</span> <span class="keyword">and</span> self.G.rendering_kwargs[<span class="string">&#x27;reg_type&#x27;</span>] == <span class="string">&#x27;monotonic-fixed&#x27;</span>:</span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Dmain: Minimize logits for generated images.</span></span><br><span class="line">        loss_Dgen = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Dmain&#x27;</span>, <span class="string">&#x27;Dboth&#x27;</span>]:</span><br><span class="line">            loss_Dgen.mean().mul(gain).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Dmain: Maximize logits for real images.</span></span><br><span class="line">        <span class="comment"># Dr1: Apply R1 regularization.</span></span><br><span class="line">        <span class="keyword">if</span> phase <span class="keyword">in</span> [<span class="string">&#x27;Dmain&#x27;</span>, <span class="string">&#x27;Dreg&#x27;</span>, <span class="string">&#x27;Dboth&#x27;</span>]:</span><br><span class="line">            ...</span><br><span class="line">            (loss_Dreal + loss_Dr1).mean().mul(gain).backward()</span><br></pre></td></tr></table></figure>
<p>​    我们可以看到各种loss，他们根据此时的phase以及相关的配置，进入不同的分支，然后计算完毕后backward计算梯度。而生成器和判别器的调用和逻辑被打包进了<code>run_G</code>和<code>run_D</code>，这是下一个层级需要分析的内容。</p>
<h5 id="Non-saturating-or-saturating"><a href="#Non-saturating-or-saturating" class="headerlink" title="Non-saturating or saturating"></a>Non-saturating or saturating</h5><p>​    首先，GAN最初的损失函数可以写作：</p>
<script type="math/tex; mode=display">
\min_G \max_DL\left( D,G \right) =\mathbb{E} _{x\sim p_{data}}\log \left[ D\left( x \right) \right] +\mathbb{E} _{z\sim p_{gen}}\log \left[ 1-D\left( G\left( z \right) \right) \right]</script><p>​    这个式子是将GAN的训练写成了一个极大极小的优化过程，但这样的写法不好引入后面要说的各种正则项。所以我们将其写成更一般的写法：</p>
<script type="math/tex; mode=display">
L_G=-\mathbb{E} _{z\sim p_{gen}}\log \left[ D\left( G\left( z \right) \right) \right] 
\\
L_D=-\left[ \mathbb{E} _{x\sim p_{data}}\log \left[ D\left( x \right) \right] +\mathbb{E} _{z\sim p_{gen}}\log \left[ 1-D\left( G\left( z \right) \right) \right] \right]
\\</script><p>​    在原文中，可以会看到一种说法，叫作非饱和（non-saturating）的生成器损失，它其实指代的就是上式中的$L_G$，饱和（saturating）的写法是：</p>
<script type="math/tex; mode=display">
L_G=\mathbb{E} _{z\sim p_{gen}}\log \left[ 1-D\left( G\left( z \right) \right) \right]</script><p>​    这两者的不同之处在于，由于判别器往往会比生成器训练的快，所以一开始生成器生成的图片，大概率都会被判别器判为假。所以这导致$D(G(z))$往往很接近0。考虑$\log \left( 1-x \right) $的导函数$-\frac{1}{1-x}$，会发现此时导数值近似于1。同时注意到，如果$x$如果接近1，此时的导数值（的绝对值）会很大。</p>
<p>​    而朴素意义上，我们想要的是在训练早期，有一些大的梯度值；在训练后期，有一些小的梯度值。这种损失下刚好与我们的初衷相违背，尤其在$x$接近0时，导数值有上界。所以我们称这种损失为饱和损失。</p>
<p>​    而当非饱和时，此时关心的是$-\log x $，其导函数为寻常的$-\frac{1}{x}$，所以在初期，$x$接近0时，可以提供一些比较大的导数值，所以称其为非饱和；然后在末期，$x$接近1时，导数值会很小，符合我们的想法。</p>
<blockquote>
<p>这样操作自然会导致梯度爆炸的隐患，所以在training_loop.py的295行，misc模块中的nan_to_num函数中实现了一次截断（clamp）：<code>return torch.clamp(input.unsqueeze(0).nansum(0), min=neginf, max=posinf, out=out)</code></p>
</blockquote>
<center>
    <img src='/images/eg3d_2.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<h5 id="R1-regularization"><a href="#R1-regularization" class="headerlink" title="R1 regularization"></a>R1 regularization</h5><p>​    还有一项技术是R1正则化，这个是2018年在<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1801.04406.pdf">Which Training Methods for GANs do actually Converge</a>里系统讨论的。这个技术并不是那么好理解，我们这里就挑着说了。EG3D里用的R1正则化（其实也就是styleGAN2用的），是对<strong>判别器的在真实数据分布上的梯度</strong>进行惩罚：</p>
<script type="math/tex; mode=display">
R_1\left( \psi \right) =\frac{\gamma}{2}\mathbb{E} _{x\sim p_{data}}\left[ \left\| \nabla D_{\psi}\left( x \right) \right\| ^2 \right]</script><p>​    有人可能会联想到机器学习中的L1，L2正则化，于是会疑问：“这里不是二范数吗？为什么叫R1？”，其实这里的1只是一个角标，在那篇论文原文里，R2指的是对<strong>判别器在生成数据分布上的梯度进行惩罚</strong>，所以和取几范数无关。</p>
<p>​    为了更好的理解这个正则化，我们需要在动力学视角下再审视一下GAN。我们知道，炼丹的核心是梯度下降：</p>
<script type="math/tex; mode=display">
\theta _{n+1}=\theta _n-lr\cdot \nabla _{\theta}L\left( \theta_n \right)</script><p>​    其形式上，其实和一个离散化的动力系统是一样的，或者说是欧拉法解微分方程，$\theta$最终会在其参数空间里留下一条轨迹。在有些时候我们可能不会关心这个轨迹，但再GAN中，我们面临这样的极大极小的博弈，此时考察这个轨迹可以带给我们一些很好的认识。</p>
<p>​    对于GAN，我们认为其系统由两部分参数组成：$\theta=(\theta_G,\theta_D)$​，所以此时GAN的更新就是下面的交替使用梯度下降的过程：</p>
<script type="math/tex; mode=display">
\theta _{G}^{\left( n+1 \right)}=\theta _{G}^{\left( n \right)}-lr\cdot \nabla _{\theta _G}L_G\left( \theta _{G}^{\left( n \right)},\theta _{D}^{\left( n \right)} \right) 
\\
\theta _{D}^{\left( n+1 \right)}=\theta _{D}^{\left( n \right)}-lr\cdot \nabla _{\theta _D}L_D\left( \theta _{G}^{\left( n \right)},\theta _{D}^{\left( n \right)} \right)</script><p>​    如果我们考虑一个，很简单的一维的GAN。具体来说，我们要拟合的样本分布，仅有一个样本点，即0。而生成器的参数为$\theta$（一个标量），判别器的参数为$\phi$（一个标量）。生成器不管输入什么，都只输出当前的$\theta$。而判别器采用一个最简单的线性决策的机制：$\phi \cdot x$。</p>
<p>​    这个玩具GAN的机制非常巧妙，基本符合了我们对GAN的一些想象：最开始的时候，生成器不知道要生成什么数字，判别器由于也没有经过训练，不知道0是真实样本，所以会对输入的数乘上$\phi$来作为输出。理想情况下，生成器会慢慢往0生成，然后由于0乘任何数都是0，最后判别器也无法区分所接收到的“0”是真实数据还是生成器生成的0。</p>
<blockquote>
<p>由于这个GAN最终拟合的是一个只在$x=0$处有值的分布，这是一种奇异函数，常用于信号与系统学科中。又叫狄拉克函数，所以这个玩具GAN也叫Dirac-GAN。</p>
</blockquote>
<p>​    所以在这个特别的GAN中，$L_D$和$L_G$可以写成更特殊的形式。由于真实样本只有0这个点，所以$L_D$的一项直接变成常数了。以及生成器的输出一直是$\theta$，所以也不需要写$z\sim p_{gen}$这样的采样了和令人头大的期望符号了：</p>
<script type="math/tex; mode=display">
L_G=-\log \left[ \sigma \left( \phi \cdot \theta \right) \right] 
\\
L_D=-\log \left[ 1-\sigma \left( \phi \cdot \theta \right) \right] 
\\</script><p>​    注意这里的$\sigma(\cdot)$，这是我们熟悉的sigmoid函数，用来把值……放到0~1之间的。一般在写$D(x)$的时候都默认最后有一层softmax了，这里需要强调一下。</p>
<p>​    此时梯度交替下降的过程也可以约化为（考验高中求导）：</p>
<script type="math/tex; mode=display">
\theta ^{\left( n+1 \right)}=\theta ^{\left( n \right)}-lr\cdot \left( \left( 1-\sigma \left( \phi ^{\left( n \right)}\cdot \theta ^{\left( n \right)} \right) \right) \cdot \phi ^{\left( n \right)} \right) 
\\
\phi ^{\left( n+1 \right)}=\phi ^{\left( n \right)}-lr\cdot \left( -\sigma \left( \phi ^{\left( n \right)}\cdot \theta ^{\left( n \right)} \right) \cdot \theta ^{\left( n \right)} \right)</script><p>​    所以$\theta=(0,0)$是这组系统最合理的解，或者说是博弈的平衡点。但遗憾的是，实践表明，朴素的GAN的训练过程做不到这一点，他们会一直转圈，很难收敛到$(0,0)$：</p>
<center>
    <img src='/images/eg3d_3.gif' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    有趣的是，我们是可以说明它没法收敛的。假设在$(0,0)$附近的一个去心邻域内作泰勒展开，$\sigma(\cdot)$函数的泰勒级数为：</p>
<script type="math/tex; mode=display">
\sigma \left( t \right) =\frac{1}{2}+\frac{1}{4}t-\frac{1}{48}t^3+\frac{1}{480}t^5...</script><p>​    对这个邻域内的$\nabla _{\theta}L_G\left( \theta ,\phi \right) ,\nabla _{\phi}L_D\left( \theta ,\phi \right) $​作泰勒展开，发现此时这个动态过程变为了：</p>
<script type="math/tex; mode=display">
\theta ^{\left( n+1 \right)}=\theta ^{\left( n \right)}-lr\cdot \frac{\phi ^{\left( n \right)}}{2}
\\
\phi ^{\left( n+1 \right)}=\phi ^{\left( n \right)}-lr\cdot \left( -\frac{\theta ^{\left( n \right)}}{2} \right)</script><p>​    整理上式，我们注意到了如下差分方程：</p>
<script type="math/tex; mode=display">
\left( \theta ^{\left( n+2 \right)}-\theta ^{\left( n+1 \right)} \right) -\left( \theta ^{\left( n+1 \right)}-\theta ^{\left( n \right)} \right) =-\frac{1}{4}\cdot lr^2\cdot \theta ^{\left( n \right)}</script><p>​    熟悉差分方程的解法的话，我们会知道这代表一个三角函数的周期解，即只要初值不是0，就会一直震荡下去。</p>
<p>​    但如果使用R1正则化，即此时的判别器损失为：</p>
<script type="math/tex; mode=display">
L_D=-\left[ \mathbb{E} _{x\sim p_{data}}\log \left[ D\left( x \right) \right] +\mathbb{E} _{z\sim p_{gen}}\log \left[ 1-D\left( G\left( z \right) \right) \right] \right] +\frac{\gamma}{2}\mathbb{E} _{x\sim p_{data}}\left[ \left\| \nabla D\left( x \right) \right\| ^2 \right]
\\
=-\log \left[ 1-\sigma \left( \phi \cdot \theta \right) \right] +\frac{\gamma}{2}\phi ^2</script><p>​    此时我们会发现：</p>
<center>
    <img src='/images/eg3d_4.gif' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    这个系统得以收敛了。是不是很神奇？</p>
<p>​    上述的玩具实验其实带来了许多丰富的观察，我们注意到，让判别器不要“更新的那么快”，会有助于GAN找到更合适的状态。这其实就是R1正则化的目的，因为判别器往往要比生成器“厉害”的多，在Dirac-GAN中，我们看到的那种圆形轨迹，实际上可以理解为生成器每次的“进步”，都完全被判别器“看破”了。于是就导致，每次判别器都在“割草”，每次生成器都在徒劳无功的“白给”。两边都没有任何进步。</p>
<p>​    同时，考虑在不施加正则化时，在$(0,0)$附近泰勒展开时，判别器和生成器之间类似三角函数般的周期性波动。其可以理解为是在稳定解附近的“震荡”，通过R1正则化，可以减少这种“震荡”。这同样是为什么现在成熟的GAN技术都必备权重滑动平均（EMA）的原因。</p>
<p>​    详细的收敛性证明可以参见18年那篇论文原文，这里就不讨论了。其实如何丝滑的训练GAN，在18~21年很受讨论。有着许许多多的GAN，但好像现在只有R1正则化成为了标配。可能是得以于其实践简单的原因。</p>
<h5 id="Density-regularization"><a href="#Density-regularization" class="headerlink" title="Density regularization"></a>Density regularization</h5><p>​    这个正则项与上一个相比，可真是容易理解多了。以及这个正则项应该是第二版论文里才写进去的，第一版里应该是没有的。这个密度正则项就像一把刻刀，说的是如果我现在已经把整个体素场隐式表达好了，我希望相邻之间的体密度不要相差很大。这样可以保证后面几何形状的光滑和现实。</p>
<blockquote>
<p> For each generated scene in the batch, we randomly sample points x in the volume and also<br>sample additional ‘perturbed’ points that are offset with a small amount Gaussian noise δx. Our density regularization loss is an L1 loss that minimizes the difference between<br>the estimated densities σ(x) and σ(x + δx).</p>
</blockquote>
<p>​    这个其实是传统计算机视觉中常用的全变分，只不过当时是用来处理2D图片里的一些low-level任务，这里取其思想用来雕刻高保真的几何了。</p>
<p>​    但在loss.py的StyleGAN2Loss的实现里，还有两种可选的密度正则化方式monotonic-detach和monotonic-fixed，这两种无论选哪一个，原来的密度正则化都会执行。这两种的意思好像是多加一个沿z轴负半轴的方向令体密度单调递减的约束，但正文里也没提，issues里和各种平台也没人问，鉴定为是废案。</p>
<h3 id="“EG3D”"><a href="#“EG3D”" class="headerlink" title="“EG3D”"></a>“EG3D”</h3><p>​    经过前面的，前置知识以后，我们终于可以开始分析EG3D本身了。然而这里的细节也有好多，我们逢山开路吧。在拆开介绍各种细节之前，我们需要将最开始的那个pipeline分成三个部分，然后进行一些比较“high-level”的概括：</p>
<center>
    <img src='/images/eg3d_5.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    红色的部分是映射网络（Mapping Network），绿色的部分是生成器，蓝色的部分是判别器。下面我们按照这三个部分来展开。我们要意识到，这里的生成器虽然画的很复杂，但本质上还是生成一张2D图片。只不过和普通的2D GAN直接生成图片不同，这里是生成一个隐式的3D表示，然后按照体渲染的路子，表征出一张2D的图片。所以这会导致下文中的“生成器”有着不同的涵义，一个意思是绿色框所标记的，整个这个产生2D图片的部分；另一个是单纯的图中的那个StyleGAN2 Generator。</p>
<h4 id="Mapping-Network"><a href="#Mapping-Network" class="headerlink" title="Mapping Network"></a>Mapping Network</h4><p>​    我们从StyleGAN2Loss中的<code>run_G</code>入手：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_G</span>(<span class="params">self, z, c, swapping_prob, neural_rendering_resolution, update_emas=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> swapping_prob <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        c_swapped = torch.roll(c.clone(), <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        c_gen_conditioning = torch.where(torch.rand((c.shape[<span class="number">0</span>], <span class="number">1</span>), device=c.device) &lt; swapping_prob, c_swapped, c)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c_gen_conditioning = torch.zeros_like(c)</span><br><span class="line"></span><br><span class="line">    ws = self.G.mapping(z, c_gen_conditioning, update_emas=update_emas)</span><br><span class="line">    <span class="keyword">if</span> self.style_mixing_prob &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">with</span> torch.autograd.profiler.record_function(<span class="string">&#x27;style_mixing&#x27;</span>):</span><br><span class="line">            cutoff = torch.empty([], dtype=torch.int64, device=ws.device).random_(<span class="number">1</span>, ws.shape[<span class="number">1</span>])</span><br><span class="line">            cutoff = torch.where(torch.rand([], device=ws.device) &lt; self.style_mixing_prob, cutoff, torch.full_like(cutoff, ws.shape[<span class="number">1</span>]))</span><br><span class="line">            ws[:, cutoff:] = self.G.mapping(torch.randn_like(z), c, update_emas=<span class="literal">False</span>)[:, cutoff:]</span><br><span class="line">    gen_output = self.G.synthesis(ws, c, neural_rendering_resolution=neural_rendering_resolution, update_emas=update_emas)</span><br><span class="line">    <span class="keyword">return</span> gen_output, ws</span><br></pre></td></tr></table></figure>
<p>​    我们可以发现，就像StyleGAN2一样，我们都是先“mapping”然后再“synthesis”，但这里有两个分支，一个是<code>swapping_prob</code>，另一个是<code>style_mixing_prob</code>。</p>
<h5 id="pose-swapping-regularization"><a href="#pose-swapping-regularization" class="headerlink" title="pose swapping regularization"></a>pose swapping regularization</h5><p>​    <code>swapping_prob</code>是EG3D里的设置，它说的是“我们在训练时，要以一定的概率，将输入进Mapping Network的相机姿态替换成另一个随机的相机姿态。”</p>
<blockquote>
<p>we randomly swap the conditioning pose in P with another random pose with 50% probability during training.</p>
</blockquote>
<p>​    这个机制并不显然，我们应该意识到三个问题，①怎么替换的？②为什么要替换？③相机姿态为什么要输入进Mapping Network？</p>
<p>​    对于①，这两行代码给出了答案：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c_swapped = torch.roll(c.clone(), <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">c_gen_conditioning = torch.where(torch.rand((c.shape[<span class="number">0</span>], <span class="number">1</span>), device=c.device) &lt; swapping_prob, c_swapped, c)</span><br></pre></td></tr></table></figure>
<p>​    c作为输入进来的一批相机位姿，在这里维度应该是[B, 25]，所以roll的目的是将它在第一个维度上向右循环移动一位。这样就可以打乱相机位姿了，因为用随机数采样生成相机位姿，会比较复杂，比如应用拒绝采样，不如这样简单。然后下一行代码会从打乱后的c和原始的c中，进行选择，从而实现了以一定的概率来打乱姿态。</p>
<p>​    对于②和③，我们要从Mapping Network开始说起。Mapping Network本身只是一个8层MLP，它最初是在StyleGAN中引入的。这个操作的动机是为了在无监督的条件下解耦一些数据集里的特征，比如，在此之前的GAN，都是直接将生成的高斯噪声直接送入生成器，那本质上是要将一个高维的高斯分布揉成数据集需要的样子。但数据集的分布往往不可能那么的“对称”，所以在这个揉搓的过程中，许多的属性（attributes）/特征（features）会耦合在一起，但如果用一个映射网络对高斯分布进行映射，理论上就有了调整分布的机会。我们一般将Mapping Network输出的结果记作$\mathbf{w}$，映射后张成的空间记作$\mathcal{W}$（intermediate latent space）。</p>
<p>​    实际上StyleGAN的实验表明，确实只需要8层MLP这样的机制，加以反向传播，就可以自动学到解耦的特征。这可能是神经网络的一种偏好，这让我联想到物理里的“最小能量原理”，可能解耦的特征可以让这个系统变得更简单，于是优化就往这个方向优化了。</p>
<p>​    所以在EG3D的问题中，他们关注的是在生成高保真的3D人脸时，由于人在面对镜头时往往会下意识的微笑。这使得相机位姿和“微笑”这个属性，耦合在了一起。所以要将相机姿态也输入Mapping Network来解耦。</p>
<p>​    那么为什么，EG3D里又引入了一个奇怪的“替换成另一个相机姿态”的机制？我们需要来看一下相机位姿在不同部分的作用，在Mapping Network里，相机位姿是一种“condition”，它会导致生成器部分生成的3D表达的变化；在生成器部分，相机位姿只是单纯在对刚才那个3D表示作体渲染时的角度；在判别器部分，相机位姿也是一种“condition”，告诉判别器当前图片是从哪个角度拍摄的，作为判别器判别的依据。</p>
<p>​    所以如果输入给Mapping Network的相机位姿和输入给生成器作体渲染的位姿一直正确且一致，那么整个模型就会意识到一个省事的办法：只要保证生成的这个3D表示在特定位姿下渲染出来的是张人脸就好了。这会导致平凡解的产生，如原文在附录里所描述的：</p>
<center>
    <img src='/images/eg3d_6.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    原文将这种现象称为“广告牌（billboard）”，还是很生动形象的。</p>
<p>​    所以他们就采用将输入给Mapping Network的位姿进行随机打乱这样的措施，来实现一种正则化。在测试时，输入给Mapping Network的位姿其实是固定的，然后通过改变体渲染时的位姿，来得到一个比较有一致性的效果。因为位姿多少都会影响输出的$\mathbf{w}$里的一些除去位姿以外的属性，比如背景。</p>
<h5 id="style-mixing-regularization"><a href="#style-mixing-regularization" class="headerlink" title="style mixing regularization"></a>style mixing regularization</h5><p>​    这一个风格混合的正则化来自于StyleGAN，实际上Mapping Network计算得到的$\mathbf{w}$，并不是一口气就输入进后面的网络的。出于特征解耦的目的，以及在深度神经网络中“浅层一般是结构（低频）信息，深层都是细节（高频）信息”的原教旨主义，$\mathbf{w}$会被切分成若干块，每一块送进不同层级的Synthesis block。这在代码中的体现是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, ws, **block_kwargs</span>):</span><br><span class="line">    block_ws = []</span><br><span class="line">    <span class="keyword">with</span> torch.autograd.profiler.record_function(<span class="string">&#x27;split_ws&#x27;</span>):</span><br><span class="line">        misc.assert_shape(ws, [<span class="literal">None</span>, self.num_ws, self.w_dim])</span><br><span class="line">        ws = ws.to(torch.float32)</span><br><span class="line">        w_idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> res <span class="keyword">in</span> self.block_resolutions:</span><br><span class="line">            block = <span class="built_in">getattr</span>(self, <span class="string">f&#x27;b<span class="subst">&#123;res&#125;</span>&#x27;</span>)</span><br><span class="line">            block_ws.append(ws.narrow(<span class="number">1</span>, w_idx, block.num_conv + block.num_torgb))</span><br><span class="line">            w_idx += block.num_conv</span><br><span class="line"></span><br><span class="line">    x = img = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> res, cur_ws <span class="keyword">in</span> <span class="built_in">zip</span>(self.block_resolutions, block_ws):</span><br><span class="line">        block = <span class="built_in">getattr</span>(self, <span class="string">f&#x27;b<span class="subst">&#123;res&#125;</span>&#x27;</span>)</span><br><span class="line">        x, img = block(x, img, cur_ws, **block_kwargs)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>
<p>​    所以所谓style mixing，就是为了让$\mathbf{w}$不同维度之间尽可能解耦，“切断”他们的相关性。这个一个机制就是说，对于一个高斯噪声$z_1$计算出的$\mathbf{w}_1$，再生成一个$z_2$对应的$\mathbf{w}_2$，然后将$\mathbf{w}_1$和$\mathbf{w}_2$作交叉。这样，就隐式的给模型创造了一个“$\mathbf{w}$的各个维度越解耦越好生成”的偏置。</p>
<h5 id="Truncation-trick"><a href="#Truncation-trick" class="headerlink" title="Truncation trick"></a>Truncation trick</h5><p>​    在作推理时，当我们运行Mapping Network时，传参里会带一个<code>--trunc=0.7</code>。这是一个在StyleGAN最后被提及的一个小巧的trick。它的基本思想是考虑到数据集分布不均衡，有些采样密度比较低的区域生成器可能学习的不是那么好。为了提高生成图像的平均质量，在采样时考虑$\mathcal{W}$空间里分布的质心$\mathbf{\bar{w}}$，然后对采样一个$z$，计算出的$\mathbf{w}$，线性插值一下：</p>
<script type="math/tex; mode=display">
\mathbf{w}^{'}=\mathbf{\bar{w}}+\psi \left( \mathbf{w}-\mathbf{\bar{w}} \right)</script><p>​    这里的$\psi$就是上面的截断系数。</p>
<h4 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h4><p>​    在生成器的部分，要先用StyleGAN2的backbone，这个backbone的实现细节我们就不展开了，我们重点要关注这个tri-plane representation。</p>
<h5 id="Tri-plane-3D-representation"><a href="#Tri-plane-3D-representation" class="headerlink" title="Tri-plane 3D representation"></a>Tri-plane 3D representation</h5><p>​    如果抛开代码，前置知识，这个”三平面表示“其实是EG3D最为影响深远的一个技术。后面的许多工作都沿用了这一点。在此之前，有一些工作，例如$\pi$-GAN，是纯隐式表达整个3D场的。也就是说如果到了要做渲染的那一步，你想计算$N$个点的颜色和体密度，需要直接计算$N$次生成器的前向传播，这样会很慢。另一种是完全显式的给出体素网格（但这种一般都是data source是3D object的情况了，和我们现在讨论的不完全一样。）但这种的占的空间又很大（几个GB都不止）。</p>
<p>​    所以EG3D里提出了这么一个”hybrid“的方案。StyleGAN2的生成器backbone会计算出一个256×256×96的特征图，我们可以认为3D场的信息被存储在了里面。举一个极端的例子：如果此时backbone输出的不是96张特征图，而就是一个，可能，1000×1000×1000×4的Tensor。那么我好像可以直接输入一组$(x,y,z)$，去这个Tensor里查，得到RGB和体密度（也就是完全给出体素网格，先不考虑光场）。但现在的输出是256×256×96的，被编码后的表示，我们需要将其解码出来。</p>
<p>​    所以三平面表示天才的地方在于，它是一个对偶的思路。它将96张特征图每3个分为一组，每一组里的3个特征图，分别看作三个正交的平面，然后从这三个平面构造的坐标系下去”查询“。这话非常不好理解，我们可以举个例子。假设我现在想查询的点的坐标是$(0.5, -0.75, 0.4)$，然后我有三张256×256的特征图。由于这三张图片分别充当了当前坐标系下的XY，XZ，ZY平面：</p>
<center>
    <img src='/images/eg3d_7.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>


<p>​    所以我们可以直接根据相应的坐标，找到各自平面的特征图上所对应的值。例如$(0.5,-0.75)$，我们将其对应到XY平面上，可以得到一个索引，比如$i=20,j=-15$，那么我们就可以找到XY平面上对应的特征图里，其$[20,-15]$所对应的值，作为$F_{xy}$，同理得到$F_{xz},F_{yz}$，如果坐标不那么圆满，就双线性插值一下。之后将$F_{xy},F_{xz},F_{yz}$加起来，作为一个小解码器的输入，然后解码后得到RGB和体密度。这种办法的好处是，得到的这些特征图，作为在给定$\mathbf{w}$下的3D场的一种隐式表示，只需要计算一次。后面synthesis函数里的<code>use_cached_backbone</code>，<code>self._last_planes</code>等选项就是这么做的。所以它在时间和空间上都取得了一个权衡。</p>
<p>​    为了更好的理解这个过程，我们现在追踪一下相关代码。在<code>./training/triplane.py</code>里，<code>TriPlaneGenerator</code>类的<code>synthesis</code>方法里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">synthesis</span>(<span class="params">self, ws, c, neural_rendering_resolution=<span class="literal">None</span>, update_emas=<span class="literal">False</span>, cache_backbone=<span class="literal">False</span>, use_cached_backbone=<span class="literal">False</span>, **synthesis_kwargs</span>):</span><br><span class="line">    cam2world_matrix = c[:, :<span class="number">16</span>].view(-<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">    intrinsics = c[:, <span class="number">16</span>:<span class="number">25</span>].view(-<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> neural_rendering_resolution <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        neural_rendering_resolution = self.neural_rendering_resolution</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.neural_rendering_resolution = neural_rendering_resolution</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a batch of rays for volume rendering</span></span><br><span class="line">    ray_origins, ray_directions = self.ray_sampler(cam2world_matrix, intrinsics, neural_rendering_resolution)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create triplanes by running StyleGAN backbone</span></span><br><span class="line">    N, M, _ = ray_origins.shape</span><br><span class="line">    <span class="keyword">if</span> use_cached_backbone <span class="keyword">and</span> self._last_planes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        planes = self._last_planes</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        planes = self.backbone.synthesis(ws, update_emas=update_emas, **synthesis_kwargs)</span><br><span class="line">    <span class="keyword">if</span> cache_backbone:</span><br><span class="line">        self._last_planes = planes</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape output into three 32-channel planes</span></span><br><span class="line">    planes = planes.view(<span class="built_in">len</span>(planes), <span class="number">3</span>, <span class="number">32</span>, planes.shape[-<span class="number">2</span>], planes.shape[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform volume rendering</span></span><br><span class="line">    feature_samples, depth_samples, weights_samples = self.renderer(planes, self.decoder, ray_origins, ray_directions, self.rendering_kwargs) <span class="comment"># channels last</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reshape into &#x27;raw&#x27; neural-rendered image</span></span><br><span class="line">    H = W = self.neural_rendering_resolution</span><br><span class="line">    feature_image = feature_samples.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(N, feature_samples.shape[-<span class="number">1</span>], H, W).contiguous()</span><br><span class="line">    depth_image = depth_samples.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(N, <span class="number">1</span>, H, W)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run superresolution to get final image</span></span><br><span class="line">    rgb_image = feature_image[:, :<span class="number">3</span>]</span><br><span class="line">    sr_image = self.superresolution(rgb_image, feature_image, ws, noise_mode=self.rendering_kwargs[<span class="string">&#x27;superresolution_noise_mode&#x27;</span>], **&#123;k:synthesis_kwargs[k] <span class="keyword">for</span> k <span class="keyword">in</span> synthesis_kwargs.keys() <span class="keyword">if</span> k != <span class="string">&#x27;noise_mode&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: sr_image, <span class="string">&#x27;image_raw&#x27;</span>: rgb_image, <span class="string">&#x27;image_depth&#x27;</span>: depth_image&#125;</span><br></pre></td></tr></table></figure>
<p>​    代码先根据此时相机外参和内参，计算出该位姿下，所要求分辨率下，光线的原点<code>ray_origins</code>和方向<code>ray_directions</code>。然后，之前mapping计算得到的ws会输入进synthesis网络里，计算得到planes。</p>
<p>​    planes最开始是[B, 96, 256, 256]，然后被处理成[B, 3, 32, 256, 256]。然后进入了这一行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_samples, depth_samples, weights_samples = self.renderer(planes, self.decoder, ray_origins, ray_directions, self.rendering_kwargs)</span><br></pre></td></tr></table></figure>
<p>​    于是我们跳转进<code>./training/volumetric_rendering/render.py</code>里，<code>ImportanceRender</code>的<code>forward</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, planes, decoder, ray_origins, ray_directions, rendering_options</span>):</span><br><span class="line">    self.plane_axes = self.plane_axes.to(ray_origins.device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> rendering_options[<span class="string">&#x27;ray_start&#x27;</span>] == rendering_options[<span class="string">&#x27;ray_end&#x27;</span>] == <span class="string">&#x27;auto&#x27;</span>:</span><br><span class="line">        ray_start, ray_end = math_utils.get_ray_limits_box(ray_origins, ray_directions, box_side_length=rendering_options[<span class="string">&#x27;box_warp&#x27;</span>])</span><br><span class="line">        is_ray_valid = ray_end &gt; ray_start</span><br><span class="line">        <span class="keyword">if</span> torch.<span class="built_in">any</span>(is_ray_valid).item():</span><br><span class="line">            ray_start[~is_ray_valid] = ray_start[is_ray_valid].<span class="built_in">min</span>()</span><br><span class="line">            ray_end[~is_ray_valid] = ray_start[is_ray_valid].<span class="built_in">max</span>()</span><br><span class="line">        depths_coarse = self.sample_stratified(ray_origins, ray_start, ray_end, rendering_options[<span class="string">&#x27;depth_resolution&#x27;</span>], rendering_options[<span class="string">&#x27;disparity_space_sampling&#x27;</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Create stratified depth samples</span></span><br><span class="line">        depths_coarse = self.sample_stratified(ray_origins, rendering_options[<span class="string">&#x27;ray_start&#x27;</span>], rendering_options[<span class="string">&#x27;ray_end&#x27;</span>], rendering_options[<span class="string">&#x27;depth_resolution&#x27;</span>], rendering_options[<span class="string">&#x27;disparity_space_sampling&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    batch_size, num_rays, samples_per_ray, _ = depths_coarse.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Coarse Pass</span></span><br><span class="line">    sample_coordinates = (ray_origins.unsqueeze(-<span class="number">2</span>) + depths_coarse * ray_directions.unsqueeze(-<span class="number">2</span>)).reshape(batch_size, -<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">    sample_directions = ray_directions.unsqueeze(-<span class="number">2</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, samples_per_ray, -<span class="number">1</span>).reshape(batch_size, -<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    out = self.run_model(planes, decoder, sample_coordinates, sample_directions, rendering_options)</span><br><span class="line">    colors_coarse = out[<span class="string">&#x27;rgb&#x27;</span>]</span><br><span class="line">    densities_coarse = out[<span class="string">&#x27;sigma&#x27;</span>]</span><br><span class="line">    colors_coarse = colors_coarse.reshape(batch_size, num_rays, samples_per_ray, colors_coarse.shape[-<span class="number">1</span>])</span><br><span class="line">    densities_coarse = densities_coarse.reshape(batch_size, num_rays, samples_per_ray, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fine Pass</span></span><br><span class="line">    N_importance = rendering_options[<span class="string">&#x27;depth_resolution_importance&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> N_importance &gt; <span class="number">0</span>:</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Aggregate</span></span><br><span class="line">        rgb_final, depth_final, weights = self.ray_marcher(all_colors, all_densities, all_depths, rendering_options)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        rgb_final, depth_final, weights = self.ray_marcher(colors_coarse, densities_coarse, depths_coarse, rendering_options)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rgb_final, depth_final, weights.<span class="built_in">sum</span>(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>​    在这里我们可以看到光线按照原点和方向进行了采样，然后进入了<code>run_model</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_model</span>(<span class="params">self, planes, decoder, sample_coordinates, sample_directions, options</span>):</span><br><span class="line">    sampled_features = sample_from_planes(self.plane_axes, planes, sample_coordinates, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, box_warp=options[<span class="string">&#x27;box_warp&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    out = decoder(sampled_features, sample_directions)</span><br><span class="line">    <span class="keyword">if</span> options.get(<span class="string">&#x27;density_noise&#x27;</span>, <span class="number">0</span>) &gt; <span class="number">0</span>:</span><br><span class="line">        out[<span class="string">&#x27;sigma&#x27;</span>] += torch.randn_like(out[<span class="string">&#x27;sigma&#x27;</span>]) * options[<span class="string">&#x27;density_noise&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>​    这里的<code>self.plane_axes</code>是一个[3, 3, 3]的常数张量，由如下函数定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_planes</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Defines planes by the three vectors that form the &quot;axes&quot; of the</span></span><br><span class="line"><span class="string">    plane. Should work with arbitrary number of planes and planes of</span></span><br><span class="line"><span class="string">    arbitrary orientation.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor([[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">                            [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]],</span><br><span class="line">                            [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]], dtype=torch.float32)</span><br></pre></td></tr></table></figure>
<p>​    这里，每一个3×3的矩阵，可以这么来<strong>理解</strong>：前两行是它代表的平面，第三行可以看成是前两行叉乘的结果。例如第一个矩阵的第一行是[1, 0, 0]，这代表x轴的单位向量，然后第二行是[0, 1, 0]，是y轴的单位向量，所以这个矩阵代表XY平面。其实这个第三行，乃至这个矩阵的出现非常奇怪，可能是为了凑一个可逆矩阵，来和后面的代码匹配上。</p>
<blockquote>
<p>如果第一行和第二行线性无关，那么第一行与第二行叉乘的结果必然也和他们线性无关，所以张成的矩阵满秩。</p>
</blockquote>
<p>​    所以这个常数张量代表了XY，XZ，ZX平面！这显然是个错误，置顶的<a target="_blank" rel="noopener" href="https://github.com/NVlabs/eg3d/issues/67">issues</a>里讨论了这一点，但这个错误其实没有那么的严重。</p>
<blockquote>
<p>出于保证论文复现性以及重新训练的成本，作者们并没有在main-branch里修复这个问题，他们开了一个新分支fixed_triplanes，然后社区里有热心群众重训了ckpt。</p>
</blockquote>
<p>​    然后我们来看<code>sample_from_planes()</code>，注意此时输入的<code>sample_coordinates</code>已经是通过光线原点，光线方向，采样得到的坐标点了（世界坐标系下）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_from_planes</span>(<span class="params">plane_axes, plane_features, coordinates, mode=<span class="string">&#x27;bilinear&#x27;</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, box_warp=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">assert</span> padding_mode == <span class="string">&#x27;zeros&#x27;</span></span><br><span class="line">    N, n_planes, C, H, W = plane_features.shape</span><br><span class="line">    _, M, _ = coordinates.shape</span><br><span class="line">    plane_features = plane_features.view(N*n_planes, C, H, W)</span><br><span class="line"></span><br><span class="line">    coordinates = (<span class="number">2</span>/box_warp) * coordinates <span class="comment"># <span class="doctag">TODO:</span> add specific box bounds</span></span><br><span class="line"></span><br><span class="line">    projected_coordinates = project_onto_planes(plane_axes, coordinates).unsqueeze(<span class="number">1</span>)</span><br><span class="line">    output_features = torch.nn.functional.grid_sample(plane_features, projected_coordinates.<span class="built_in">float</span>(), mode=mode, padding_mode=padding_mode, align_corners=<span class="literal">False</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(N, n_planes, M, C)</span><br><span class="line">    <span class="keyword">return</span> output_features</span><br></pre></td></tr></table></figure>
<p>​    注意这里的<code>plane_axes</code>是刚才讨论的[3, 3, 3]的张量，<code>plane_features</code>是之前计算出来，处理成[B, 3, 32, 256, 256]的那个。然后在这里这个<code>plane_feautures</code>又被揉搓成[3×B, 32, 256, 256]了，然后这个时候的<code>coordinates</code>维度是[B, M, 3]，这里的M是每条光线上需要采样的数量和一共发出的光线数的乘积。</p>
<p>​    然后全体坐标会被缩放一下，缩放倍数是<code>(2/box_warp)</code>，在生成人脸和猫猫头的数据集里，<code>box_warp</code>都是1，所以就是为了把坐标放大一倍。这样做是因为下面两行用到的<code>torch.nn.functional.grid_sample</code>接收的是[-1, 1]的输入，而原始的坐标的范围是[-0.5, 0.5]。</p>
<p>​    然后这个<code>project_onto_planes()</code>就是为了将3D的坐标投影到2D平面上，但由于这里所说的平面都是XY，XZ，YZ这样的，所以其实只要一顿索引+切片就好了。但作者可能为了严谨性和普适性，还是要用矩阵乘法来向量化实现一遍（所以就有了上面的<code>generate_planes()</code>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">project_onto_planes</span>(<span class="params">planes, coordinates</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Does a projection of a 3D point onto a batch of 2D planes,</span></span><br><span class="line"><span class="string">    returning 2D plane coordinates.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Takes plane axes of shape n_planes, 3, 3</span></span><br><span class="line"><span class="string">    # Takes coordinates of shape N, M, 3</span></span><br><span class="line"><span class="string">    # returns projections of shape N*n_planes, M, 2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N, M, C = coordinates.shape</span><br><span class="line">    n_planes, _, _ = planes.shape</span><br><span class="line">    coordinates = coordinates.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, n_planes, -<span class="number">1</span>, -<span class="number">1</span>).reshape(N*n_planes, M, <span class="number">3</span>)</span><br><span class="line">    inv_planes = torch.linalg.inv(planes).unsqueeze(<span class="number">0</span>).expand(N, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>).reshape(N*n_planes, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    projections = torch.bmm(coordinates, inv_planes)</span><br><span class="line">    <span class="keyword">return</span> projections[..., :<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>​    由于有3个平面，所以<code>coordinates</code>沿着新增加的一个维度进行广播，最终形状为[3×B, M, 3]，然后输入的planes（这里其实是上一层函数里的planes_axes，[3, 3, 3]），计算一下其逆阵，也沿批处理的维度广播一下，变为[B, 3, 3, 3]的，为了批量的进行矩阵乘法，再将第一维合并进去得到[3×B, 3, 3]。最终用torch.bmm()批量相乘，乘完以后得到形状为[3×B, M, 3]的结果，切片只取前两位。</p>
<p>​    这个事情其实非常奇怪，尤其是这里求个逆阵，可能是想符合数学上的坐标变换时的某种形式：</p>
<script type="math/tex; mode=display">
\boldsymbol{y}=\mathbf{P}^{-1}\boldsymbol{x}</script><p>​    但其实这完全没有必要啊，这三个用坐标轴定义来的矩阵都非常简单，而且是正交阵，其逆阵就是其转置。整个<code>project_onto_planes()</code>的操作其实完全就是想：</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix}
    x&        y&        z\\
\end{matrix} \right] \left[ \begin{matrix}
    0&        1&        0\\
    0&        0&        1\\
    1&        0&        0\\
\end{matrix} \right] =\left[ \begin{matrix}
    z&        x&        |y\\
\end{matrix} \right]</script><p>​    来得到相关坐标的索引，可能就是因为这块的冗余，导致他们最开始放的那个版本，这个地方投影投错了。实际上，如果返回去看<code>generate_planes()</code>的定义，你会发现如果在<code>project_onto_planes()</code>里不求planes的逆，结果就正好能表示XY，XZ，YZ平面了。</p>
<p>​    所以回到<code>sample_from_planes()</code>，现在坐标已经处理好了，而在整个网格里进行采样的这个过程，torch里正好有个<code>torch.nn.functional.grid_sample</code>可以负责，总之这个函数就封装了按照计算得到的2D投影去查特征图，然后双线性插值的过程。所以这个函数接收[3×B, 32, 256, 256]的planes和[3×B, 1, M, 2]的坐标，托广播机制的福，可以直接向量化的采样到[3×B, 32, 1, M]的张量，然后permute将其调整为[3×B, M, 1, 32]，然后reshape成[B, 3, M, C]。这就是采样出的<code>output_features</code>。第二个维度上的3就是原文中的$(F_{xy},F_{xz},F_{yz})$。</p>
<p>​    然后回到<code>run_model()</code>，下面就是这一行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out = decoder(sampled_features, sample_directions)</span><br></pre></td></tr></table></figure>
<p>​    这里的decoder，就是一个很小的decoder，它的定义是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OSGDecoder</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_features, options</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden_dim = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.net = torch.nn.Sequential(</span><br><span class="line">            FullyConnectedLayer(n_features, self.hidden_dim, lr_multiplier=options[<span class="string">&#x27;decoder_lr_mul&#x27;</span>]),</span><br><span class="line">            torch.nn.Softplus(),</span><br><span class="line">            FullyConnectedLayer(self.hidden_dim, <span class="number">1</span> + options[<span class="string">&#x27;decoder_output_dim&#x27;</span>], lr_multiplier=options[<span class="string">&#x27;decoder_lr_mul&#x27;</span>])</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sampled_features, ray_directions</span>):</span><br><span class="line">        <span class="comment"># Aggregate features</span></span><br><span class="line">        sampled_features = sampled_features.mean(<span class="number">1</span>)</span><br><span class="line">        x = sampled_features</span><br><span class="line"></span><br><span class="line">        N, M, C = x.shape</span><br><span class="line">        x = x.view(N*M, C)</span><br><span class="line"></span><br><span class="line">        x = self.net(x)</span><br><span class="line">        x = x.view(N, M, -<span class="number">1</span>)</span><br><span class="line">        rgb = torch.sigmoid(x[..., <span class="number">1</span>:])*(<span class="number">1</span> + <span class="number">2</span>*<span class="number">0.001</span>) - <span class="number">0.001</span> <span class="comment"># Uses sigmoid clamping from MipNeRF</span></span><br><span class="line">        sigma = x[..., <span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;rgb&#x27;</span>: rgb, <span class="string">&#x27;sigma&#x27;</span>: sigma&#125;</span><br></pre></td></tr></table></figure>
<p>​    这只是两层MLP，相比而言朴素的NeRF需要8+1层MLP来表征，这确实省下了不少（因为相当一部分工作在StyleGAN2的生成器backbone里做了）。值得注意的是这个解码器并没有使用<code>ray_directions</code>，颜色并没有随角度变化，我推测这一是为了保持多视图上的一致性，二是对于猫猫头和人脸，确实没有什么Non-Lambertian的东西需要建模吧。</p>
<p>​    然后[B, 3, M, C]的sampled_features，其沿着3的那个维度求平均，然后形状变为[B, M, C]，然后准备对特征进行解码，先调整形状为[B×M, C]以符合Linear的传参要求，然后输出的维度为[B×M, 1 + 32]。然后再复原回[B, M, 1 + 32]，然后选取33维里第一个那个是体密度，其余的都是RGB。</p>
<p>​    太好啦，终于计算得到体密度[B, M, 1]和RGB表示[B, M, 32]了。然后你是不是这时候才发现，“你这RGB是不是不太对啊，你这根本就不是RGB啊？”，别急。我们现在还在<code>ImportanceRender</code>的<code>forward</code>里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">out = self.run_model(planes, decoder, sample_coordinates, sample_directions, rendering_options)</span><br><span class="line">colors_coarse = out[<span class="string">&#x27;rgb&#x27;</span>]</span><br><span class="line">densities_coarse = out[<span class="string">&#x27;sigma&#x27;</span>]</span><br><span class="line">colors_coarse = colors_coarse.reshape(batch_size, num_rays, samples_per_ray, colors_coarse.shape[-<span class="number">1</span>])</span><br><span class="line">densities_coarse = densities_coarse.reshape(batch_size, num_rays, samples_per_ray, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>​    先拆开，准备光线追踪。体密度从[B, M, 1]-&gt;[B, num_rays, samples_per_ray, 1]，RGB从[B, M, 32]-&gt;[B, num_rays, samples_per_ray, 32]。然后光线追踪是从这句进入的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rgb_final, depth_final, weights = self.ray_marcher(colors_coarse, densities_coarse, depths_coarse, rendering_options)</span><br></pre></td></tr></table></figure>
<p>​    这里的<code>self.ray_marcher</code>其实实现的比较简洁，通过看<code>ray_marcher.py</code>的实现可以知道和原版NeRF基本是一样的，但从代码的痕迹上可以看出参考了Mip-NeRF，但不涉及任何光锥。所以这里就不展开了。我们主要关注一下输出中的rgb_final。是的，你想的没错，它的维度还会是[B, num_rays, 32]，那个光线追踪只是单纯的数值积分，没有引入什么“着色”的机制。</p>
<p>​    于是我们终于又回到了triplane这里，得到了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_samples, depth_samples, weights_samples = self.renderer(planes, self.decoder, ray_origins, ray_directions, self.rendering_kwargs) <span class="comment"># channels last</span></span><br></pre></td></tr></table></figure>
<p>​    这里的feature_samples，然后它被整理成了一张图片的形状：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reshape into &#x27;raw&#x27; neural-rendered image</span></span><br><span class="line">H = W = self.neural_rendering_resolution</span><br><span class="line">feature_image = feature_samples.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(N, feature_samples.shape[-<span class="number">1</span>], H, W).contiguous()</span><br></pre></td></tr></table></figure>
<p>​    然后，选取特征图的前三个通道：“你们分别就是R，G，B啦！”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run superresolution to get final image</span></span><br><span class="line">rgb_image = feature_image[:, :<span class="number">3</span>]</span><br><span class="line">sr_image = self.superresolution(rgb_image, feature_image, ws, noise_mode=self.rendering_kwargs[<span class="string">&#x27;superresolution_noise_mode&#x27;</span>], **&#123;k:synthesis_kwargs[k] <span class="keyword">for</span> k <span class="keyword">in</span> synthesis_kwargs.keys() <span class="keyword">if</span> k != <span class="string">&#x27;noise_mode&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: sr_image, <span class="string">&#x27;image_raw&#x27;</span>: rgb_image, <span class="string">&#x27;image_depth&#x27;</span>: depth_image&#125;</span><br></pre></td></tr></table></figure>
<p>​    然后这一坨，其实分辨率只有128×128，确实不太够看。于是就送入了一个超分网络提升到512×512。至此，已成艺术。</p>
<blockquote>
<p>“其实feature_image中的前3个成员最开始并没有意识到什么，他们跟其他29个通道一样都是一坨浆糊。但可能是冥冥之中使命（梯度）的召唤，他们开始变得有意义。人生又何尝不是这样？”——佚名</p>
</blockquote>
<h5 id="Tri-plane-intuition"><a href="#Tri-plane-intuition" class="headerlink" title="Tri-plane intuition"></a>Tri-plane intuition</h5><p>​    好的，我们大概知道这个三平面表示怎么计算了。但是，为什么我总感觉这个表示有些没头没脑呢？这个事情应该有个逻辑啊。或者说，有个背后的直觉啊。我最开始审视这个方法的时候，我想到了大一上的工图。</p>
<blockquote>
<p>为了找到答案，我有在网上搜索一些，但鲜有人提这回事。我翻到了EG3D一作在油管上上传的一个<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=2SGhKAX6x4g">视频</a>，发现他居然也是拿三视图说事，然后一句带过了。</p>
</blockquote>
<p>​    这背后的灵感可以从稀疏网格和张量分解里窥探一下。我们输入$(x,y,z)$，往往想知道一个辐射场$\mathcal{F} _{\left( x,y,z \right)}$处的特征（体密度，颜色）。但如果我本就把voxel的这种归纳偏置带出来，建立一个稀疏的可学习的网格，这样就可以省去用MLP去”synthesis”，可以直接在这个网格上查。如果需要，再用一个规模小很多的MLP去提取一下。这最早是<a target="_blank" rel="noopener" href="https://alexyu.net/plenoxels/">Plenoxels</a>先成功实现的。</p>
<p>​    而网格作为一个3D张量，倒也不需要表征的那么稠密，可以使用张量分解技术，这样我们只需要学习更小数量的元素就好了。例如CP分解（Canonical polyadic decomposition），给定$\mathcal{A} \in \mathbb{R} ^{I_0\times I_1\times I_2}$​，其可以被表达为：</p>
<script type="math/tex; mode=display">
\mathcal{A} =\sum_{r=1}^R{\mathbf{a}_{0,r}\otimes \mathbf{a}_{1,r}\otimes \mathbf{a}_{2,r}}</script><p>​    这里$\mathbf{a}_{0,r}\in \mathbb{R} ^{I_0},\mathbf{a}_{1,r}\in \mathbb{R} ^{I_1},\mathbf{a}_{2,r}\in \mathbb{R} ^{I_2}$，可以理解为将一个稠密的张量，分解为若干向量组的外积。用matlab，randn三个向量，求取张量积</p>
<center>
    <img src='/images/eg3d_8.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

<p>​    可以看见这是一种有充沛表征空间的表示，$R$个这样的比较稀疏的表示（或者说“子空间”）加起来，逼近$\mathcal{A}$，是一种非常合理的操作。这种分解方式也不唯一，<a target="_blank" rel="noopener" href="https://apchenstu.github.io/TensoRF/">TensoRF</a>在此基础上引入了更一般的VM分解（vector-matrix decomposition）。</p>
<p>​    在EG3D中，我们没有直接从网格/向量开始优化，换句话说，我们没有确定张量分解的分解方式。我们直接从StyleGAN2生成器的backbone里得到了特征图的表示，假设它是一种富有表现力的结构，那么通过3个3个一组，然后每3个张成一个子空间。最后将采样得到的$(F_{xy},F_{xz},F_{yz})$取平均，即求和。</p>
<p>​    直觉来讲，求和确实是一个比求积更“稳定”，变化更“少”的操作。所以最近的一篇工作<a target="_blank" rel="noopener" href="https://sarafridov.github.io/K-Planes/">k-planes</a>里认为应该求积，并且用局部响应的图示来说明了一下。EG3D的作者<a target="_blank" rel="noopener" href="https://github.com/NVlabs/eg3d/issues/99">回答</a>时也说当时是出于简单考虑。</p>
<p>​    上面的代码分析里，我们知道求和后的张量，最后输入解码器时的“通道数”为C，所以在那两层MLP里，这些每个子空间里采样得到的张量和，就近似上面的CP分解一样，“求和”在了一起。最终作为一个3D场的表示。这基本就是我认为的“三平面表示”背后的直觉了。</p>
<p>​    值得注意的是，其实这一节里提到的那三个工作，应该都是在EG3D以后出现的，所以不得不佩服于EG3D作者们当时的洞见。</p>
<h4 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h4><p>​    判别器这里并没有很多的内容，只是一些很小的改动。我们可以看一下<code>run_D</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_D</span>(<span class="params">self, img, c, blur_sigma=<span class="number">0</span>, blur_sigma_raw=<span class="number">0</span>, update_emas=<span class="literal">False</span></span>):</span><br><span class="line">    blur_size = np.floor(blur_sigma * <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">if</span> blur_size &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">with</span> torch.autograd.profiler.record_function(<span class="string">&#x27;blur&#x27;</span>):</span><br><span class="line">            f = torch.arange(-blur_size, blur_size + <span class="number">1</span>, device=img[<span class="string">&#x27;image&#x27;</span>].device).div(blur_sigma).square().neg().exp2()</span><br><span class="line">            img[<span class="string">&#x27;image&#x27;</span>] = upfirdn2d.filter2d(img[<span class="string">&#x27;image&#x27;</span>], f / f.<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.augment_pipe <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        augmented_pair = self.augment_pipe(torch.cat([img[<span class="string">&#x27;image&#x27;</span>],</span><br><span class="line">                                                torch.nn.functional.interpolate(img[<span class="string">&#x27;image_raw&#x27;</span>], size=img[<span class="string">&#x27;image&#x27;</span>].shape[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>, antialias=<span class="literal">True</span>)],</span><br><span class="line">                                                dim=<span class="number">1</span>))</span><br><span class="line">        img[<span class="string">&#x27;image&#x27;</span>] = augmented_pair[:, :img[<span class="string">&#x27;image&#x27;</span>].shape[<span class="number">1</span>]]</span><br><span class="line">        img[<span class="string">&#x27;image_raw&#x27;</span>] = torch.nn.functional.interpolate(augmented_pair[:, img[<span class="string">&#x27;image&#x27;</span>].shape[<span class="number">1</span>]:], size=img[<span class="string">&#x27;image_raw&#x27;</span>].shape[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>, antialias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    logits = self.D(img, c, update_emas=update_emas)</span><br><span class="line">    <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<p>​    为了防止多视角歧义，将低分辨率RGB图进行上采样，和超分后的图并在一起作为6通道的输入，送入判别器。（如果是真实图像，那就模糊一下，然后再拼在一起。）</p>
<p>​    这里的blur其实也比较有来头了，最开始引入是在StyleGAN3，当然也不排除在此之前人们就这么用，来防止NN过分拟合高频部分了。</p>
<h3 id="Trailer"><a href="#Trailer" class="headerlink" title="Trailer"></a>Trailer</h3><p>​    写了这么多，就为了这时候呢。</p>
<p>​    EG3D是一项大工程，所以它的Requirements做的很好：</p>
<blockquote>
<ul>
<li>1–8 high-end NVIDIA GPUs. We have done all testing and development using V100, RTX3090, and A100 GPUs.</li>
</ul>
</blockquote>
<p>​    尤其当它提到，在这些显卡上测试了以后，就最好用这些显卡来跑，我在autodl上随便拉的是一个4090，然后我就吃到了<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/pytorch3d/issues/1399">这个</a>。</p>
<p>​    老老实实在单卡3090上就可以玩了捏：</p>
<center>
<video id="video" controls style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_run_1.mp4" type="video/mp4" >
</video>
</center>

<p>​    其脚本还提供了不同的风格向量之间插值的功能：</p>
<center>
<video id="video" controls style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_run_2.mp4" type="video/mp4" >
</video>
</center>

<p>​    可以看到最后的结果在性别，肤色上丝滑的过渡。</p>
<p>​    但这些都是随机数摇骰子的结果，EG3D并没有提供更多样化的condition的操作。毕竟GAN没有diffusion那么好”manipulate“，就像小说《诗云》里，“李白”得到了整个汉字的排列组合，但也找不到里面哪些是比李白更好的诗一样。</p>
<p>​    但别急，我们遇到的问题没有那么富有思辨，我们可以用GAN inversion这项技术从$\mathcal{W}$解算出某张图片对应的$\mathbf{w}$。具体来说使用的<a target="_blank" rel="noopener" href="https://github.com/danielroich/PTI">PTI</a>（Pivotal Tuning Inversion），这个PTI基本就是先微调风格向量，然后再微调一下生成器。</p>
<p>​    有一个非官方的<a target="_blank" rel="noopener" href="https://github.com/oneThousand1000/EG3D-projector">仓库</a>将其与EG3D整合在了一起。但是，让它运行起来还是花了一些功夫的。</p>
<p>​    首先，对于我们随手找来的一张图片（wild image），需要进行预处理。需要在<a target="_blank" rel="noopener" href="https://github.com/sicxu/Deep3DFaceRecon_pytorch/tree/6ba3d22f84bf508f0dde002da8fff277196fef21">Deep3DFaceRecon</a>的库的基础上进行操作。在安装这个库的时候，我们一定要敏锐的注意到yml文件里用的是python3.6，和tensorflow 1.15.0，这在我愉快的开箱即用时产生了多米诺骨牌效应，具体来说：</p>
<p>​    我在一台有3090的服务器上安装了这个环境，然后我发现，我一顿conda env创建的环境好像把默认的cuda给卸了，然后我发现我不能用GPU。因为30系及以上的卡用的安培架构，cuda版本必须在11以上，新装的cuda是10.几。然后我以为我可以纯CPU的作inference，但那里面好像在某一步需要一个光栅化的东西，于是我只能推倒重来换成2080ti。</p>
<blockquote>
<p>非常害人，当时我又开了一台3090的实例，然后发现我一load预训练的pkl怎么就爆显存，哪都排查了一遍，比如pkl丢包，僵尸进程，torch-cuda版本等，然后发现换台机器就没事了。所以autodl上的有些卡可能已经超出使用寿命了，要当心。</p>
</blockquote>
<p>​    然后我又卡在了nvdiffrast那里，先是缺依赖，又说<code>[F glutil.cpp:338] eglInitialize() failed Aborted (core dumped)</code>，然后在issues里找到将所有<code>dr.RasterizeGLContext</code>换成<code>dr.RasterizeCudaContext</code>，然后我居然发现我没有后者？于是我又卸了重来了一遍，发现原始仓库导向的那个库是旧的，作者说了更新指向了但我不知道为什么还是指向旧的。</p>
<p>​    于是这么一顿奇幻漂流以后，终于把预处理的部分搞定了。预处理基本就是两步，一，将这个图片里的人脸裁剪出来；二，估计相机位姿出来。根据我的测试，第一步的裁剪非常重要，裁剪对inversion后的结果影响最大。</p>
<center>
<video id="video" controls style="max-width: 400px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_run_3.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 400px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_run_4.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    然后就可以愉快的进行PTI了。我选取了FFHQ数据集里的数据，2077捏人面板和游戏内的截图：</p>
<center>
    <img src='/images/eg3d_ffhq.png' style="width: 250px; height: 250px;">
     <img src='/images/eg3d_v.png' style="width: 250px; height: 250px;">
    <img src='/images/eg3d_2077.png' style="width: 250px; height: 250px;">
</center>

<center>
    <img src='/images/eg3d_ffhq.gif' style="width: 250px; height: 250px;">
     <img src='/images/eg3d_v.gif' style="width: 250px; height: 250px;">
    <img src='/images/eg3d_2077.gif' style="width: 250px; height: 250px;">
</center>

<p>​    但上面gif最后的结果是微调风格向量后的，接下来第二步微调生成器，我好像一调，超分的功能就受损了。下面是最终的结果：</p>
<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_ffhq.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_v.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/eg3d_2077.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    可以发现，对于FFHQ上的真实人脸，效果是最好的。对于虚拟合成的女V，其五官生成的也很标志，但可能头发确实过于抽象了，没法生成出那种卷的效果来。至于强尼银手的那个case，我感觉可能是光影的原因。但这也是事实意义上的”单视图三维人脸重建“，所以还是很好玩的。</p>
<p>​    以及最后我还进行了一个经典的OOD测试，我直接把一张动漫图片输入进去（如果老老实实走预处理的流程，其实根本就进不来，因为动漫头像上不会被arcface里的模型检测出人脸，也就不会有detection.txt，于是也就中断了。但为了搞事，直接把一个算好的位姿和图片张冠李戴也不是不行。）</p>
<center>
    <img src='/images/eg3d_miku_0.png' style="width: 250px; height: 250px;">
     <img src='/images/eg3d_miku_1.png' style="width: 250px; height: 250px;">
</center>
​    这个稀奇的结果其实揭示了一件事情，EG3D之所以可以这样不用像NeRF一样重新synthesis，是因为GAN的backbone里隐含了对”人脸“的理解（如果是猫猫头的ckpt，那就是猫脸）。显然模型并不理解动漫图片上那俩那么大的在眼睛位置上的东西是什么，于是将其演化为了”墨镜“。

​    后来出于一些原因，我多做了一些inversion的结果，探索了一些有的没的。这些inversion的结果比之前写这篇blog时质量要高一些：

<center>
    <img src='/images/inversion/eg3d_foreign1.png' style="width: 300px; height: 300px;">
     <img src='/images/inversion/eg3d_foreign2.png' style="width: 300px; height: 300px;">
    <img src='/images/inversion/eg3d_foreign3.png' style="width: 300px; height: 300px;">
</center>


<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_foreign1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_foreign2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_foreign3.mp4" type="video/mp4" >
  </video>  
</center>
<center>
    <img src='/images/inversion/eg3d_asian1.png' style="width: 300px; height: 300px;">
     <img src='/images/inversion/eg3d_asian2.png' style="width: 300px; height: 300px;">
    <img src='/images/inversion/eg3d_asian3.png' style="width: 300px; height: 300px;">
</center>


<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_asian1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_asian2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/eg3d_asian3.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    以及还有一些比较好玩的功能，例如把人变年轻：</p>
<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Foreign1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Foreign2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Foreign3.mp4" type="video/mp4" >
  </video>  
</center>

<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Asian1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Asian2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/child/Asian3.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    把人变老：</p>
<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Foreign1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Foreign2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Foreign3.mp4" type="video/mp4" >
  </video>  
</center>

<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Asian1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Asian2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/old/Asian3.mp4" type="video/mp4" >
  </video>  
</center>    

<p>​    变换性别：</p>
<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Foreign1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Foreign2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Foreign3.mp4" type="video/mp4" >
  </video>  
</center>

<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Asian1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Asian2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/gender/Asian3.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    改变表情（主要是笑脸与否）：</p>
<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Foreign1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Foreign2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Foreign3.mp4" type="video/mp4" >
  </video>  
</center>

<center>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Asian1.mp4" type="video/mp4" >
</video>
<video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Asian2.mp4" type="video/mp4" >
  </video>  
   <video id="video" controls style="max-width: 300px; max-height: 600px; width: auto; height: auto;">
    <source id="mp4" src="/images/inversion/express/Asian3.mp4" type="video/mp4" >
  </video>  
</center>

<p>​    这个是一个比较老的GAN里的把戏了，只不过这个能无痛在3D-aware GAN里做出来还是挺新奇的。</p>
<h3 id="End"><a href="#End" class="headerlink" title="End"></a>End</h3><p>​    ”薄凇缀霜洲没落朽，料峭撩盏叩销离忧。千山叠寒飞雪渡头醉深笑幸否，未道好梦枕休醒我光阴久。“</p>
<center>
    <img src='/images/eg3d_end.jpg' style="max-width: 800px; max-height: 600px; width: auto; height: auto;">
</center>

		

		
      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/img/QRcode.png">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">3DV</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">深度学习</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习//" class="article-tag-list-link color5">深度学习</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="/categories/深度学习/3DV//" class="article-tag-list-link color4">3DV</a>
        		</li>
      		
		</ul>
	</div>


      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//pan.baidu.com/share/qrcode?url=https://zjwfufu.github.io/2023/10/09/EG3D/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2023/10/22/neus_and_volsdf/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          NeuS &amp;&amp; VolSDF
        
      </div>
    </a>
  
  
    <a href="/2023/09/06/PyTorch%E4%B8%AD%E7%9A%84dataloader/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">炼丹中缺失的一课2</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                    <div class="toc-article">
                    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Overview"><span class="toc-number">1.</span> <span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Analysis"><span class="toc-number">2.</span> <span class="toc-text">Code Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#config-setting"><span class="toc-number">2.1.</span> <span class="toc-text">config setting</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#click%E5%8F%96%E4%BB%A3argsparse"><span class="toc-number">2.1.1.</span> <span class="toc-text">@click取代argsparse</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%AF%BC%E5%85%A5"><span class="toc-number">2.1.2.</span> <span class="toc-text">动态导入</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#launch-training"><span class="toc-number">2.2.</span> <span class="toc-text">launch training</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#DP%E4%B8%8EDDP%E7%9A%84%E5%85%A5%E9%97%A8"><span class="toc-number">2.2.1.</span> <span class="toc-text">DP与DDP的入门</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#training-loop"><span class="toc-number">2.3.</span> <span class="toc-text">training loop</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B2%A1%E7%94%A8%E8%BF%87sampler%EF%BC%9F"><span class="toc-number">2.3.1.</span> <span class="toc-text">没用过sampler？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%80%9C%E6%8C%81%E4%B9%85%E5%8C%96%E2%80%9D%E7%9A%84%E7%94%A8%E5%A4%84"><span class="toc-number">2.3.2.</span> <span class="toc-text">“持久化”的用处</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E5%BE%AA%E7%8E%AF%E4%BD%93"><span class="toc-number">2.3.3.</span> <span class="toc-text">构造循环体</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#accumulate-gradients"><span class="toc-number">2.4.</span> <span class="toc-text">accumulate gradients</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Non-saturating-or-saturating"><span class="toc-number">2.4.1.</span> <span class="toc-text">Non-saturating or saturating</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#R1-regularization"><span class="toc-number">2.4.2.</span> <span class="toc-text">R1 regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Density-regularization"><span class="toc-number">2.4.3.</span> <span class="toc-text">Density regularization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%80%9CEG3D%E2%80%9D"><span class="toc-number">3.</span> <span class="toc-text">“EG3D”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Mapping-Network"><span class="toc-number">3.1.</span> <span class="toc-text">Mapping Network</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#pose-swapping-regularization"><span class="toc-number">3.1.1.</span> <span class="toc-text">pose swapping regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#style-mixing-regularization"><span class="toc-number">3.1.2.</span> <span class="toc-text">style mixing regularization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Truncation-trick"><span class="toc-number">3.1.3.</span> <span class="toc-text">Truncation trick</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Generator"><span class="toc-number">3.2.</span> <span class="toc-text">Generator</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Tri-plane-3D-representation"><span class="toc-number">3.2.1.</span> <span class="toc-text">Tri-plane 3D representation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Tri-plane-intuition"><span class="toc-number">3.2.2.</span> <span class="toc-text">Tri-plane intuition</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Discriminator"><span class="toc-number">3.3.</span> <span class="toc-text">Discriminator</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Trailer"><span class="toc-number">4.</span> <span class="toc-text">Trailer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#End"><span class="toc-number">5.</span> <span class="toc-text">End</span></a></li></ol>
                    </div>
                </span>
            </div>
        </div>
        
    </div>
</aside>



  
  
  

  

  

  




   
       <section id="comments" class="comments">
         <style>
           .comments{margin:30px;padding:10px}
           @media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
         </style>
         <div id="vcomment" class="comment"></div>
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage@3.10.0/dist/av-min.js"></script>
<script src='//unpkg.com/valine@latest/dist/Valine.min.js'></script>
<script src="https://cdnjs.loli.net/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
  var notify = 'false' == true ? true : false;
  var verify = 'false' == true ? true : false;
  new Valine({
    av: AV,
    el: '#vcomment',
    notify: notify,
    app_id: "KTThWK27Eh6ekYfsqiopKv5U-gzGzoHsz",
    app_key: "422yG6fEuKk191rqIdgv7KQY",
    placeholder: "Hi~",
    avatar: "mm",
  });
</script>

     </section>
   




          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2025 张嘉伟
    	</div>
      	<div class="footer-right">
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev"></a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</script>
<script type="text/javascript" src="/./click.js">
</script>
<script  async  src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">3DV</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">计算机组成</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">深度学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">杂记</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">大二暑假</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">数学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">线性代数</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">杂项</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据结构</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">人工智能</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">信号处理</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">PDE</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数学建模</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">有限差分</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">傅里叶变换</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数值方法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">元胞自动机</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">泛函</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">优化</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">启发式算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">复变函数</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">大学物理</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">课外学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">ODE</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">电路分析</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">微机原理</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">拉普拉斯变换</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数理统计</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">最小二乘法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">时间序列</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">条件概率</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">概率论</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">概率分布</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">模式识别</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">英语</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">故障诊断</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://liaoxdu.top" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Ao Li</a>
            </li>
          
            <li class="search-li">
              <a href="https://zhf999.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Hongfeng Zhou</a>
            </li>
          
            <li class="search-li">
              <a href="https://wj-inf.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Jia Wang</a>
            </li>
          
            <li class="search-li">
              <a href="https://the-sky001.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Tiantian Wang</a>
            </li>
          
            <li class="search-li">
              <a href="https://xiejingcheng.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Jingcheng Xie</a>
            </li>
          
            <li class="search-li">
              <a href="https://cfcys.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Mingshuo Cai</a>
            </li>
          
            <li class="search-li">
              <a href="https://zhiyangliang.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Zhiyang Liang</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/people/ceng-fei-fei-81" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Yifei Zeng</a>
            </li>
          
            <li class="search-li">
              <a href="https://1zeryu.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Yukun Zhou</a>
            </li>
          
            <li class="search-li">
              <a href="https://cominclip.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Xinchen Zhang</a>
            </li>
          
            <li class="search-li">
              <a href="https://alinaya.vercel.app/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Alina Wang</a>
            </li>
          
            <li class="search-li">
              <a href="https://zijian-wu.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Zijian Wu</a>
            </li>
          
            <li class="search-li">
              <a href="https://yanwen-w.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Yanwen Wang</a>
            </li>
          
            <li class="search-li">
              <a href="https://wangli000.github.io/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Li Wang</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">挟飞仙以遨游，抱明月而长终。&lt;br /&gt;知不可乎骤得，托遗响于悲风。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.1/es5/tex-mml-chtml.min.js"></script>
</body>
</html>